--- 
title: "텍스트 분석을 통한 프로듀스X101 데뷔조 예측 "
author: "JDW"
date: "2019-12-19"
site: bookdown::bookdown_site
documentclass: book
link-citations: yes
description: "This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook."
---

# Update {-}
```
업데이트 날짜 : 2021-01-27 
업데이트 내역 :  
 1. 다중회귀분석 및 시계열 예측 모델 추가 
 2. 방송 이후 추가로 알려진 사실에 대한 내용 추가 
 3. 본문 중 잘못 서술하거나 미흡했던 내용 수정 
```

<!--chapter:end:index.Rmd-->

# Prologue 

![](C:/Users/JDW/Desktop/GIT/produceX101/img_source/producex1/final.jpg)
<center>*사진출처 : 엠넷*</center>   
<br>
   
&nbsp;조금은 시간이 지났지만 지난 2019년 여름 "프로듀스 X 101" 프로그램이 한참 방영했던 당시 진행했던 텍스트 분석입니다.
   
&nbsp;엠넷의 대표적인 방송중 하나인 프로듀스 시리즈는 매 시리즈마다 숱한 화제를 불러오며 인기를 끌었던 서바이벌 오디션 프로그램인데요. 그 중 이번에 분석한 "프로듀스 X 101"은 4번째 시리즈로서 101명의 연습생들이 방송에서 무대를 선보이고, 시청자들의 투표를 통해 최종 11명의 아이돌멤버를 선발한다는 컨셉의 방송입니다. 
   
&nbsp;이 글을 쓰고 있는 시점인 2019년 11월 현재 프로듀스 시리즈는 제작진의 투표조작 논란에 휩싸여 시청자의 투표를 통해 선발한다는 컨셉이 무색해졌지만 그래도 분석을 통해 어느 연습생이 시청자들의 관심을 받았었는지 혹은, 누가 많은 이슈를 몰고 있었는지를 수치로 확인할 수 있었기에 나름 의미있는 분석이었다고 생각이 듭니다. 
 
***

전체적인 구성은 다음과 같습니다. 
   
**1. 데이터수집**   
**2. 데이터 전처리 및 취합**   
**3. 시각화**   
**4. 모델링**   
   
&nbsp;데이터 수집 단계에서는 온라인 커뮤니티에 올라오는 시청자들의 의견을 수집하였습니다. 방송 기간중 유저들이 활발히 활동을 하였던 사이트를 대상으로 웹 스크래핑 기법을 통해 수집을 진행. 
   
&nbsp;데이터 전처리 및 취합에서는 일간별로 수집된 데이터를 확인하고, 이를 취합하여 분석에 용이한 형태로 전처리하는 과정을 담았습니다. 
   
&nbsp;취합한 데이터를 바탕으로 특징적인 부분을 시각화를 통해 탐색해 보았으며, 최종적으로 다중회귀식을 활용한 예측모델을 생성하여 모델링을 통한 예측의 과정도 정리하였습니다. 
   
&nbsp;그럼 이제 단계별로 차근차근 알아보겠습니다. 

<!--chapter:end:01-producex1.Rmd-->

# 데이터 수집

```{r, message=FALSE, include=FALSE}
library(tidyverse)
library(data.table)
library(knitr)
library(httr)
```

&nbsp;데이터 분석을 위해 가장 먼저 진행한 것은 분석의 대상이 될 데이터를 확보 하는 일 입니다.   

&nbsp;이번장에서 진행할 것은 데이터 수집에 관한 전반적인 것들 입니다.   

&nbsp;"프로듀스 X 101"은 당시 인기가 많은 프로그램이었기 때문에 다양한 웹 커뮤니티에서 방송에 대한 많은 의견들이 올라왔었습니다. 물론 이들 모두를 수집하여 분석하면 더욱 좋았겠지만 취미로 진행하였기에 커뮤니티 중 활발히 활성화가 되고 있던 한 곳을 선정하여 데이터 수집을 진행하였습니다.   
<br>

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width = '80%', fig.align='center'}
knitr::include_graphics('./img_source/producex2/dc_producexgallery.jpg')
```
<center>*웹 커뮤니티에 올라오는 글*</center>   
<br>

&nbsp;해당 커뮤니티는 방송이 인기를 끌었던 시점에는 하루에 대략 4만건의 게시물 까지 올라왔었는데요. 한참 방송이 진행중이던 06/01 부터 마지막 생방송날인 07/19 까지의 데이터를 수집하였었습니다.   

&nbsp;웹 데이터 수집을 위한 여러 방법이 있지만 R 에서 웹페이지를 수집할 때 보편적으로 사용하는 `rvest` 패키지를 주로 활용하여 스크래핑을 진행하였습니다.   
<br>

::: {.infobox .caution data-latex="{caution}"}
**주의사항!**

&nbsp;크롤링 혹은 스크래핑을 통한 데이터 수집을 진행할 경우에는 웹사이트 소유권자가 제공하는 [**robot.txt**](https://ko.wikipedia.org/wiki/%EB%A1%9C%EB%B4%87_%EB%B0%B0%EC%A0%9C_%ED%91%9C%EC%A4%80) 를 준수하며 진행해야 합니다. <br>
&nbsp;비록 의무가 아닌 권고이지만 이를 무시하고 크롤링을 진행할 경우 윤리적 문제뿐만 아니라 심할 경우 _현행법 위반_ 으로 법에 저촉되는 행위가 될 수 있습니다. 
:::
<br>

&nbsp;아래부터는 스크래핑 코드 입니다. 

## 웹 스크래핑

```{r, eval = F}
# 저장 폴더 설정 ---- 
dataFolder <- '저장폴더경로'
setwd(dataFolder)

# 사용 패키지 호출 ---- 
library(rvest)
library(httr)
library(dplyr)
library(lubridate)
library(stringr)
```
   
&nbsp;먼저 스크래핑한 데이터를 저장할 폴더와 필요한 패키지들을 호출합니다. 

```{r}
# 주소설정 ----
basic_url <- 'https://gall.dcinside.com/board/lists/?id=producex&page='
urls <- NULL
for(x in 0:999){
    urls[x + 1] <- paste0(basic_url, x + 1)
}
```

&nbsp;웹페이지의 주소를 기반으로 스크래핑을 진행하기 때문에 정보를 가져올 웹페이지의 주소를 for문을 통해서 만들어 줍니다. 

&nbsp;해당 코드를 돌리면 다음과 같은 결과값이 나옵니다. 

```{r, warning=FALSE, message=FALSE}
head(urls);tail(urls)
```

&nbsp;for문을 통해 1페이지부터 1000페이지까지 총 1000개의 웹페이지 주소가 생성되었네요.   

&nbsp;만들어진 주소들을 기반으로 스크래핑을 진행합니다. 먼저 스크래핑 정보를 담을 빈객체들을 생성합니다.   

```{r, eval = F}

# 빈 객체 생성 ----
gallMain      <- NULL
p_title       <- NULL
p_comment_num <- NULL
p_time        <- NULL
p_count       <- NULL
p_recommend   <- NULL
dc            <- NULL

```

&nbsp;본격적으로 for문을 통해 데이터를 페이지순으로 순차적으로 가져옵니다.   

```{r, eval = F }
# 스크래핑 ---- 
for(url in urls){
    
    gallMain <- GET(url, timeout(10)) %>% read_html() %>% html_nodes('.ub-content.us-post')

    p_title <- sapply(seq(1, length(gallMain)), function(x){
        gallMain[x] %>%
            html_nodes('.gall_tit.ub-word') %>%
            html_node('a') %>%
            html_text()
    })
    p_comment_num <- sapply(seq(1, length(gallMain)), function(x){
        gallMain[x] %>%
            html_nodes('.gall_tit.ub-word') %>%
            html_nodes('.reply_numbox') %>%
            html_text() %>% str_replace_all(., '[[:punct:]]', '') %>% paste(., collapse = '')
    })
    p_time <- sapply(seq(1, length(gallMain)), function(x){
        gallMain[x] %>%
            html_nodes('.gall_date') %>%
            html_attr('title')
    })
    p_count <- sapply(seq(1, length(gallMain)), function(x){
        gallMain[x] %>%
            html_nodes('.gall_count') %>%
            html_text()
    })
    p_recommend <- sapply(seq(1, length(gallMain)), function(x){
        gallMain[x] %>%
            html_nodes('.gall_recommend') %>%
            html_text()
    })

}
```

&nbsp;for문을 돌릴 시 맨 처음 만들었던 주소들 즉, `urls` 객체에 담긴 주소값을 받아서 서버에게 순차적으로 주소에 대한 정보를 요청하게 됩니다. 그렇게 응답받은 정보를 바탕으로 for문 내부에 있는 파싱코드를 수행하는게 되는데요. 각각의 객체에 해당하는 값들을(`p_title`, `p_time`...) 파싱합니다. for문 내 모든 과정을 수행하면 for문은 다음 주소를 요청하여 처음부터 다시 파싱을 진행하게 됩니다.   

```{r, eval = F}
# 데이터 프레임화 ----  
dc <- data.frame(p_title, p_comment_num, p_time, p_count, p_recommend)

# 날짜조정 ----
dc$p_time <- ymd_hms(dc$p_time)
dc <- dc[day(dc$p_time) == day(today()-1), ]
```

&nbsp;for문을 통해 수집한 각각의 객체 데이터들을 `dc` 라는 이름의 데이터프레임에 담아주었습니다. 시간을 다루는 `lubridate` 패키지의 `ymd_hms()`함수를 이용하여 글 작성 시간을 의미하는 `p_time` 데이터를 시간 데이터로 변경해 줍니다.   

&nbsp;코드는 `taskscheduleR` 패키지를 활용하여 매일 자정 무렵 자동으로 돌아가게끔 설정 했었는데요. 데이터를 매일 수집하는 것이다 보니 오직 전날에 작성된 글들만을 저장하기 위해서 `dc <- dc[day(dc$p_time) == day(today()-1), ]` 필터링 코드를 만들었습니다. 코드를 짧막하게 설명하자면 글 작성 시간을 의미하는 `dc$p_time` 이 수집하는 날 바로 하루 전 `today() - 1` 의 값과 동일한 값만을 dc객체로 새로이 담아낸 것입니다.   

```{r echo = FALSE, results = 'asis'}

dc <-readRDS('C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver/2019-06-01.rds')
dc %>% 
    select(p_title, p_comment_num, p_time, p_count, p_recommend) %>% 
    tail() %>% 
    kable()
```
<center>*스크래핑을 마친 데이터의 구조*</center>   
<br>

```{r eval = FALSE}
# 파일저장 ----
write.csv(dc, paste0(ymd(today()-1), ".rds"))
```

&nbsp;마지막으로 필터링까지 완료된 데이터를 `rds`파일로 저장합니다. 

<!--chapter:end:02-producex2.Rmd-->

# 데이터 전처리

```{r, include=FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
```

&nbsp;이번 파트는 데이터 전처리 과정을 다룹니다.   

&nbsp;스크래핑한 데이터들은 사용하기 위해서는 적합한 형태로 변환을 해야 하는 과정이 필요합니다.   

&nbsp;파일들을 R로 불러들이겠습니다. 

## 데이터 취합

```{r producex3_1, message=FALSE, cache=TRUE}
# 사용 패키지 호출 ----
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)

# for문을 활용한 데이터 불러오기 및 취합 ----
filelist <- list.files(dir) # dir : "저장된 데이터의 폴더 경로"
pxdata <- data.frame()
temp <- NULL

for(file in filelist){
    if(str_sub(file, -3, -1) == 'rds'){
        temp <- readRDS(paste(dir, file, sep = '/'))
        temp <- temp %>% select(p_title,       # 제목 
                                p_comment_num, # 댓글 수  
                                p_time,        # 글 작성 시간 
                                p_count,       # 조회수 
                                p_recommend)   # 추천수
        pxdata <- rbind(pxdata, temp)
        
        rm(temp)
    }else{
        next
    }
}
```

&nbsp;일간별로 수집했던 데이터들을 불러와 `pxdata`라는 데이터프레임에 취합 하였습니다. 이를 활용하여 분석을 진행할 예정입니다.   

## Feature Engineering

&nbsp;데이터 수집 과정을 통해 `p_title`, `p_time`, `p_count`, `p_recommend` 의 변수를 생성하였습니다. 그 중 `p_time` 변수는 게시글의 작성된 시간이 초단위까지 기록된 변수인데, 해당 변수를 활용해서 날짜, 요일과 같은 좀 더 세분화된 시간변수를 생성하도록 하겠습니다.   

```{r ,message=FALSE, cache=TRUE}
pxdata <- pxdata %>% mutate(p_ymd   = as.Date(p_time),                                        # 년-월-일 
                            p_month = as.factor(month(p_time)),                               # 월 
                            p_day   = as.factor(day(p_time)),                                 # 일 
                            p_hour  = as.factor(hour(p_time)),                                # 시간 
                            p_wday  = as.factor(lubridate::wday(as.Date(p_time), label = T))) # 요일

```

&nbsp;"프로듀스 X 101"은 매주 금요일 밤 11시에 시작하여 다음날 토요일 AM 12:30즈음 끝이 났었는데요. 데이터가 에피소드별로(매 주 방송되는 1주 간격으로) 어떻게 그리고 얼마나 변화했는지를 파악하기 위해 `lubridate`패키지의 `week()`함수를 사용하여 게시판의 글이 몇 화의 에피소드때 작성되었는지를 알리는 변수인 `p_episode` 변수를 생성하도록 하겠습니다. 매 화 방송이 끝나는 토요일부터 그 다음주 금요일까지의 기간을 하나의 에피소드 기간으로 취급하여 변수를 생성하였습니다.   

&nbsp;처음 데이터를 수집하기 시작한 날짜인 2019-06-01은 토요일로 전날 5화가 방영되던 날 이였습니다. 이 정보를 토대로 `p_episode` 변수를 생성하도록 하겠습니다.   

&nbsp;새로 생성된 시간과 관련된 변수들은 범주형 속성을 지니고 있으므로 `as.factor()`함수를 사용하여 범주형 값으로 변환했습니다.  

```{r, producex3_2}
pxdata <- pxdata %>% mutate(p_episode = week(p_ymd - 5) - 17) 
```
```{r}
pxdata %>% glimpse()
pxdata %>% summary()
is.na(pxdata) %>% colSums()
```
```{r, echo = FALSE}
pxdata %>% head(10) %>% kable() %>% kable_styling("striped") %>% scroll_box(width = "100%")
```

<br>
&nbsp;따로 저장되어 있던 데이터들을 하나로 묶고, 분석에 필요한 새로운 변수열을 생성하였습니다.   

&nbsp;마지막 에피소드는 `2019-07-19`에 방영 됐었습니다. 마지막 방송에서 진행된 시청자 문자투표는 방송이 시작한 시각인 밤 8시부터 밤 9시까지 진행이 됐었는데요. 투표가 종료된 이후의 데이터는 의미가 없으므로 데이터의 범위를 문자투표가 끝나는 시간인 `2019-07-19` 밤 9시까지로 설정하겠습니다.   
```{r}
# 일간별 데이터 갯수 확인 
table(pxdata$p_ymd)

# 마지막날 문자투표 종료 이후 데이터 삭제 
lastDay <- pxdata %>% 
    filter(p_ymd == '2019-07-19') %>% 
    filter(!p_hour %in% c(21, 22, 23, 24))

# 데이터 재 접합 
pxdata <- pxdata %>% 
    filter(p_ymd != '2019-07-19') %>% 
    rbind(lastDay)

# 데이터 확인 
table(pxdata$p_ymd)
```

&nbsp;마지막날의 데이터행이 124790개 에서 51546로 줄어든 것을 확인할 수 있습니다. 이것으로 전처리작업을 마치도록 하겠습니다.  

<!--chapter:end:03-producex3.Rmd-->

# 데이터 시각화 

```{r, include = FALSE} 
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
pxdata <- readRDS(str_glue("{dir}/pxdata.rds"))
```

&nbsp;본격적인 분석에 앞서 이전 파트에서 전처리한 데이터들을 기반으로 간단한 시각화를 진행해 볼까 합니다.   

&nbsp;데이터 시각화를 통해 지금 가지고있는 데이터의 특성을 파악하고, 특징적인 정보가 있는지를 한번 살펴 보겠습니다.   

&nbsp;먼저 앞장에서 다루었던 전처리한 데이터의 형태입니다. 

```{r producex4_2, message=FALSE}
pxdata %>% 
    head(100) %>% 
    DT::datatable(options = list(scrollX = TRUE))
```

## 회차별 게시글 수 비교 

```{r, message = FALSE}
pxdata %>% 
    group_by(p_episode) %>%
    count() 
```

```{r producex4_3, echo = FALSE, out.width="1000px"}
pxdata %>% 
    group_by(p_episode) %>% 
    summarise(n = n()) %>%
    ggplot(aes(x = as.factor(p_episode), y = n)) + 
    geom_col() + 
    geom_text(aes(label = n), size = 3, vjust = -1) + 
    labs(x = '에피소드', y = '게시글')
```

&nbsp;그래프의 x축은 방송 회차 기간을 의미하고, y축은 게시글 수를 의미합니다.   

&nbsp;방송이 진행될수록 작성된 글 수는 증가하는 면모를 보입니다.   

## 요일별 게시글 수 비교 

```{r}
pxdata %>% 
    group_by(p_wday) %>%
    count() 
```

```{r producex4_4, echo = FALSE, out.width="1000px"}
pxdata %>% 
    group_by(p_wday) %>% 
    summarise(n = n()) %>%
    ggplot(aes(x = as.factor(p_wday), y = n)) + 
    geom_col() + 
    geom_text(aes(label = n), size = 3, vjust = -1) + 
    labs(x = '요일', y = '게시글')
```

&nbsp;방송이 방영되던 금요일과, 방송이 끝난 당일인 토요일에 작성된 글 수가 많은 것을 확인할 수 있습니다.   

## 일자별 게시글 수 비교 

```{r producex4_5, out.width="1000px"}
pxdata %>% 
    group_by(p_ymd) %>% 
    count() %>% 
    mutate(p_wday = lubridate::wday(p_ymd, label = T), 
           p_md = str_sub(p_ymd, 6, 10)) %>%
    ggplot(aes(x = as.factor(p_md), y = n)) + 
    geom_col(aes(fill = p_wday)) +
    theme(axis.text.x = element_text(angle = 90, size = 7))  + 
    labs(x = '날짜', y = '게시글', fill = "")
```


```{r producex4_6, out.width="1000px"}
pxdata %>% 
    group_by(p_ymd) %>% 
    count() %>% 
    mutate(p_wday = lubridate::wday(p_ymd, label = T), 
           p_md = str_sub(p_ymd, 6, 10)) %>%
    ggplot(aes(x = reorder(as.factor(p_md), -n), y = n)) + 
    geom_col(aes(fill = p_wday)) +
    theme(axis.text.x = element_text(angle = 90, size = 7))  + 
    labs(x = '날짜', y = '게시글', fill = "")

```


```{r producex4_7, out.width="1000px"}
pxdata %>% 
    group_by(p_ymd) %>% 
    count() %>% 
    mutate(p_wday = lubridate::wday(p_ymd, label = T), 
           p_md = str_sub(p_ymd, 6, 10)) %>%
    ggplot(aes(x = as.factor(p_md), y = n)) + 
    geom_col() +
    geom_text(aes(label = n), vjust = -1, size = 2) + 
    theme(axis.text.x = element_text(size = 0))  + 
    facet_wrap(~ p_wday) + 
    labs(x = '날짜', y = '게시글')
```

&nbsp;일자별로 나누어 보았을 경우에도 금요일과 토요일에 사람들의 프로그램에 대한 관심도가 높은것을 확인할 수 있습니다. 

&nbsp;다음으로 시청자들로부터 어느 연습생의 언급량이 많았는지를 도출해 보도록 하겠습니다. 



<!--chapter:end:04-producex4.Rmd-->

# 언급량 도출
```{r, include = FALSE} 
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
library(plotly)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
pxdata <- readRDS(str_glue("{dir}/pxdata.rds"))
boylist <- readLines('C:/Users/JDW/Desktop/PROJECT/PRODUCEX/final_boylist.txt')
```

![](C:/Users/JDW/Desktop/GIT/produceX101/img_source/producex1/final.jpg)
<center>*사진출처 : 엠넷*</center>   
<br>

&nbsp;이제 분석의 마무리 작업으로 지금까지 전처리한 데이터를 기반으로 어느 연습생의 언급량이 높았었는지를 직접 확인해 볼 시간입니다. 데이터 수집부터 이전에 진행한 시각화까지 다소 짧은 분량은 아니었는데요. 이번 시각화를 통해서 분석을 마무리를 지어볼까 합니다.   

## 데이터 시각화 
 
&nbsp; 지금까지 수집한 데이터는 실제로 방송을 시청하는 시청자들이 게시판에 작성한 게시물들의 제목들(`p_title`) 입니다. 즉, 방송을 보고 투표를 할 확률이 높은 시청자들의 의견이 담긴 텍스트인데요. 분석에 앞서 한가지 가정을 했었습니다. 언급량이 높으면 높을수록 그만큼 인기도 많을 것이다 였는데요. 사람들 입에서 회자가 많이 된다는 것은 그만큼 관심과 인기가 있다는 의미이고, 그것이 투표량과도 상관이 있을것이다 가정하였습니다.   

## 분석 범위 설정
&nbsp; "프로듀스 X 101"은 101명의 연습생들이 무대에서 경연을 통해 경쟁을 펼치고, 이를 본 시청자들의 투표를 통해서 최종 11명의 아이돌 멤버를 선발한다는 컨셉의 방송인데요. 마지막 방송날에 인기가 높았던 20명의 연습생들이 생방송 무대에서 경합을 펼쳤습니다. 마지막 방송까지 살아남은 최종 20명을 대상으로 분석을 진행해 보도록 하겠습니다. 

미리 마지막 생방송에 진출한 스무명의 연습생 이름을 `final_boylist.txt` 파일에 저장해 두었었고, 이를 불러오겠습니다. 

```{r, eval = FALSE}
boylist <- readLines('./final_boylist.txt')
boylist
```

```{r, echo=FALSE}
boylist
```

&nbsp; 언급량은 연습생별로 연습생이 언급된 게시물들의 갯수가 몇개인지를 세어보는 방식으로 집계할 것입니다. 그런데 게시물들의 특성상 연습생의 fullname을 적는 경우보다 name만 적는 경우가 많이 있었기에 먼저 호출한 `boylist`에서 이름만 추출하겠습니다. 

```{r}
boylist2 <- str_sub(boylist, -2, -1) # 뒤에서 두번째 글자부터 뒤에서 첫번째 글자까지만을 저장 
boylist2
```

## 언급량 집계

### 별명 정리 
&nbsp; 글을 작성할 때 이름을 적는 경우도 있지만 경우에 따라서는 별명이나 애칭으로 부르는 경우도 더러 있었습니다. 별명이나 애칭은 대상을 지칭하는 의미에서 결국 이름으로 부르는것과 다를바가 없을 것입니다. 때문에 각 연습생별로 자주 쓰이는 별명을 사전에 조사하여 데이터에서 그 별명을 연습생의 이름으로 변경시켜주는 작업을 진행하겠습니다.   

```{r}
# 연습생별 별명 
boy_nickname <- list(
  c('욯'),               # 김요한
  c('짤랑이'),           # 김우석
  c('지녁'),             # 이진혁
  c('스누피', '식빵맨'), # 한승우
  c('밍규', '밍구'),     # 김민규
  c('조골무'),           # 조승연
  c('도깅', '도옵'),     # 남도현
  c('형깅'),             # 송형준
  c(),                   # 이은상
  c('금동'),             # 금동현
  c(),                   # 차준호
  c('표동'),             # 손동표
  c('쁘띠'),             # 황윤성
  c('말티쥬', '강미니'), # 강민희
  c(),                   # 구정모
  c(),                   # 이한결
  c('유넨'),             # 송유빈
  c('함옵', '함깅'),     # 함원진
  c('토카츄'),           # 토니
  c('마리몽')            # 이세진
)

names(boy_nickname) <- boylist

# 별명 수정 전 
pxdata %>% filter(str_detect(p_title, '욯')) %>% nrow();
pxdata %>% filter(str_detect(p_title, '요한')) %>% nrow()

# 별명 수정
for(i in seq(1, length(boylist))){
  if(length(unlist(boy_nickname[boylist[i]])) != 0){
    pxdata <- pxdata %>%
      mutate(p_title = stringi::stri_replace_all_fixed(p_title, paste(unlist(boy_nickname[i])), names(boy_nickname[i]), vectorize_all = F))
  }
}

```
&nbsp;검색을 통하여 별명을 찾아보았고, 연습생별 자주 쓰이는 별명을 `list`형식으로 저장하였습니다. 뚜렷한 별명이 없는 연습생은 공란으로 두었고, 별명의 경우이더라도 일상에서 많이 쓰이는 일반명사로 사용된 별명은 별명에서 제외하였습니다.   

```{r}
# 별명 수정 후
pxdata %>% filter(str_detect(p_title, '욯')) %>% nrow();
pxdata %>% filter(str_detect(p_title, '요한')) %>% nrow()
```

&nbsp;별명이 모두 이름으로 변경된 것을 확인할 수 있습니다. 

&nbsp;그런다음 for문을 통해 연습생별로 언급량을 집계해 보겠습니다.   

```{r, cache=TRUE}
final_boys <- c()
boys <- c()

# 연습생별 언급게시글의 개수 `final_boys` 리스트에 저장 
for(i in 1:length(boylist2)){
    final_boys[i] <- nrow(pxdata[grep(boylist2[i], pxdata$p_title), ])           
}

# 연습생 - 연습생 언급게시 개수 데이터프레임화 
boys <- data.frame(boy = boylist, 
                   mention = as.numeric(final_boys), 
                   stringsAsFactors = F) 

str(boys)
```

&nbsp;이를 시각화하여 알아보도록 하겠습니다. 

## 언급량 시각화

### Barchart
```{r, out.width="1000px"}
boys %>% 
    ggplot(aes(x = boy, y = mention)) + 
    geom_col() + 
    geom_text(aes(label = mention), vjust = -.5, size = 2) + 
    theme(axis.text.x = element_text(angle = 45)) 
```

```{r, out.width="1000px"}
boys %>% 
    ggplot(aes(x = reorder(boy, -mention), y = mention)) + 
    geom_col() + 
    geom_text(aes(label = mention), vjust = -.5, size = 2) + 
    theme(axis.text.x = element_text(angle = 45)) 

```

&nbsp;시각화를 진행한 결과 **김우석**, **조승연**, **김민규**, **이은상**, **구정모**, **김요한**, **남도현**, **송형준**, **한승우**, **강민희**, **이진혁** 순으로 언급량이 많은것을 확인 할 수 있었습니다.   

&nbsp;하지만 이것은 전체기간을(06/01 ~ 07/19) 대상으로 집계한 언급량이기 때문에 연습생들의 시간에 따른 언급량의 변화는 찾아 볼 수가 없네요. 방송이 진행되면서 멋진 무대를 소화해 낸 연습생은 순위가 올라간 경우도 있었고, 반대로 다른 여러 요인들로 인해 인기가 하락한 경우도 종종 볼 수 있었습니다.   

&nbsp;그렇다면 이번에는 에피소드별로 연습생들의 언급량이 어떻게 변화했는지를 확인해 보도록 하겠습니다.   

### 에피소드별 언급량 변화 

```{r, message=FALSE, cache=TRUE}
# 에피소드별 언급량
temp_mention <- c()
episode_mention <- c()

for(i in seq(1, 20)){
  print(boylist[i])
  temp_mention <- pxdata %>%
    filter(str_detect(p_title, boylist2[i])) %>%
    group_by(p_episode) %>%
    summarise(mention = n()) %>%
    mutate(boy = boylist[i])

  episode_mention <- rbind(episode_mention, temp_mention)
}

```

```{r}
DT::datatable(episode_mention)
```

&nbsp;이렇게 에피소드별, 연습생별로 나누어진 데이터를 Barchart를 통해 시각화 해보겠습니다.   

```{r, out.width="1000px"}

episode_mention %>% 
    ggplot(aes(x = as.factor(p_episode), y = mention)) + 
    geom_col() + 
    geom_text(aes(label = mention), vjust = -1, size = 2) + 
    facet_wrap( ~ boy) + 
    labs(x = '에피소드', y = '언급량')
```

&nbsp;확실히 시간에 따른 연습생의 언급량이 어떻게 변화하였는지가 파악이 됩니다. 그렇지만 값이 높은 순서로 정렬이 되어 있지 않아 한눈에 파악하기 약간 어려운거 같은데 11주차 방송 기간을 기준으로 연습생의 언급량을 재정렬 해보겠습니다.   

### Barchart(11화 언급량 기준 정렬)

```{r, out.width="1000px"}
episode_level <- episode_mention %>%
  filter(p_episode == 11) %>%
  arrange(desc(mention)) %>% 
  .$boy

episode_mention %>% 
  mutate(boy = factor(boy, levels = episode_level)) %>% 
  ggplot(aes(x = as.factor(p_episode), y = mention)) + 
  geom_col() + 
  geom_text(aes(label = mention), vjust = -1, size = 2) + 
  facet_wrap( ~ boy) + 
  labs(x = '에피소드', y = '언급량')
```

&nbsp;11회차를 기준으로는 **조승연**, **구정모**, **김우석**, **김민규**, **한승우**, **김요한**, **남도현**, **이은상**, **이진혁**, **금동현**, **송형준** 순으로 언급된 것을 볼 수 있습니다. 실제로 데뷔한 연습생들과 비교해 보니 전체 11명중 7명이 속하네요.(물론 잘못된 투표였다는 발표가 있었지만요.) 그렇지만 온라인 커뮤니티에서 시청자들이 어떤 연습생에 대해 많이 얘기하고 관심이 있어하는지를 엿볼 수 있던 기회였습니다.   

&nbsp;이제 마지막으로 Bump chart를 제작하여 연습생들의 언급도가 어떻게 변화하였는지를 확인해 보도록 하겠습니다.   

### Bump chart

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width = '80%', fig.cap="Bump chart", fig.align='center'}
knitr::include_graphics('./img_source/producex5/Bump-Chart-unnamed-chunk-7-1.png')
```

&nbsp;Bump chart는 순위가 있는 값들을 시각화하는데 사용이 되는 차트인데 위와 같이 순위의 변화를 관찰할때 유용하게 사용되는 차트입니다.  

```{r, message=FALSE, warning=FALSE}
library(plotly)

# 테마 설정 
my_theme <- function() {

    # Colors
    color.background = "white"
    color.text = "#22211d"

    # Begin construction of chart
    theme_bw(base_size=15) +

        # Format background colors
        theme(panel.background = element_rect(fill=color.background, color=color.background)) +
        theme(plot.background  = element_rect(fill=color.background, color=color.background)) +
        theme(panel.border     = element_rect(color=color.background)) +
        theme(strip.background = element_rect(fill=color.background, color=color.background)) +

        # Format the grid
        theme(panel.grid.major.y = element_blank()) +
        theme(panel.grid.minor.y = element_blank()) +
        theme(axis.ticks       = element_blank()) +

        # Format the legend
        # theme(legend.position = "none") +

        # Format title and axis labels
        theme(plot.title       = element_text(color=color.text, size=20, face = "bold")) +
        theme(axis.title.x     = element_text(size=14, color="black", face = "bold")) +
        theme(axis.title.y     = element_text(size=14, color="black", face = "bold", vjust=1.25)) +
        theme(axis.text.x      = element_text(size=10, vjust=0.5, hjust=0.5, color = color.text)) +
        theme(axis.text.y      = element_text(size=10, color = color.text)) +
        theme(strip.text       = element_text(face = "bold")) +

        # Plot margins
        theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
}

# 데이터 세팅 
pxdata_bump <- episode_mention %>%
  group_by(p_episode) %>%
  arrange(-mention) %>%
  mutate(ranking   = row_number()) 

# Bump Chart
pxdata_plotly <- pxdata_bump %>%
  ggplot    (aes(x = as.integer(p_episode), y = ranking, group = boy)) +
  geom_line (aes(color = boy, alpha = 1), size = 1.2) +
  geom_point(aes(color = boy, alpha = 1), size = 3) +
  geom_point(color ='#FFFFFF', size = 1) +
  scale_x_continuous(breaks = 1:7, minor_breaks = 1:7, expand = c(.05, .05), labels = seq(5, 11)) +
  scale_y_reverse(breaks = 1:20) +
  geom_text(data = pxdata_bump %>% filter(p_episode == 5),
            aes(label = boy, x = 0.6), hjust = 1, fontface = 'bold', color = '#888888', size = 4) +
  geom_text(data = pxdata_bump %>% filter(p_episode == 11),
            aes(label = boy, x = 7.4), hjust = 1, fontface = 'bold', color = '#888888', size = 4) +
  labs(x = '에피소드', y = '순위', alpha = "", color = "") +     
  my_theme() 

gp <- ggplotly(pxdata_plotly) %>% 
      config(displayModeBar = F) %>% 
      layout(title = list(text = paste0('<b>', 
                                        '[PRODUCE X 101] WEEKLY BUMPCHART', 
                                        '<br>', 
                                        '<sup>', 
                                        '에피소드별 언급량 순위 변동', 
                                        '</sup>',  
                                        '</b>')),
             legend = list(y = 0), 
             margin = list(t = 100))
  
gp
```
<center>*우측 이름을 더블클릭하면 개별 추세를 명확하게 확인할 수 있습니다.*</center>   

<br>

&nbsp;Bumpchart는 `ggplot`의 차트객체를 반응형 차트 형태로 변환시켜주는 `plotly` 패키지의 `ggplotly()` 함수를 사용하여 제작하였습니다. 마우스액션을 통해 좀더 세분화하여 차트를 탐색하여 볼 수 있습니다.   

***

&nbsp;지금까지 데이터를 수집부터, 시각화 분석까지의 전반적인 과정들을 한번 훝어보았습니다. 예전에 취미삼아 혼자서만 분석하고 묵혀만 두었던 프로젝트였는데 블로그를 구축하고, 많은 분들께 공유할 수 있게 되어서 감회가 새롭네요. R 유저로서 `blogdown` 패키지로 블로그를 만들어 보고 싶었는데 올해가 넘어가기 전에 그 일을 끝마칠수 있어서 개인적으로 뿌듯합니다.   

&nbsp;처음 작성한 글이라 미흡한 글이긴 하지만 도움이나 흥미가 있었기를 바라며 이만 마무리 짓도록 하겠습니다. 지금까지 긴글 읽어주셔서 감사합니다.   

<!--chapter:end:05-producex5.Rmd-->

# 모델링 
```{r, include = FALSE} 
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
library(plotly)
library(dlookr)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
boylist <- readLines('C:/Users/JDW/Desktop/PROJECT/PRODUCEX/final_boylist.txt')
boylist2 <- str_sub(boylist, -2, -1)
```
&nbsp;방송이 끝난 2019년으로부터 지금은 1년이란 시간이 넘게 흘렀습니다. 그동안 "프로듀스 X 101" 조작 논란에 대한 재판이 진행이 되었었고, 재판 결과에 따른 새로운 사실도 드러났었습니다. 처음 이 글을 마친 2019년 연말에는 단순히 언급량을 집계하여 과거의 언급된 량을 순위처럼 취급하고 글을 끝 마쳤었는데, 1년이 지난 지금 새로운 방식으로 순위를 집계 해 보고자 합니다. 더불어 재판과 관련된 이슈또한 짚어보고 글을 마쳐보는것으로 하겠습니다.   

## 파일 불러오기 & 구조 확인 
&nbsp;지난번에 전처리까지 끝마쳤던 데이터를 불러와 구조를 확인해 보도록 하겠습니다.   
```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(stringr)
library(dlookr)

pxdata <- readRDS(str_glue('{dir}/pxdata.rds'))
pxdata %>% head()
pxdata %>% summary()
pxdata %>% glimpse()
pxdata %>% dlookr::diagnose()
```
&nbsp;분석에 대상이 되는 데이터는 총 11개의 변수와 1542120행으로 이루어진 것을 확인 할 수 있습니다. 데이터 수집 당시 획득한 변수로는 게시물의 제목을 의미하는 `p_title`과 게시물에 있는 댓글의 갯수를 의미하는 `p_comment_num`, 게시물의 작성시간인 `p_time`, 게시물의 조회수를 의미하는 `p_count`, 그리고 게시물 추천수의 갯수인 `p_recommend` 변수가 있는데요. 오늘은 이들 변수를 활용하여 예측 모델링을 수행해보는 과정을 알아보겠습니다.    

## 예측 방식 설정 
&nbsp;이전에 했던 작업들을 되짚어보면 단순히 연습생의 언급량 즉, 온라인 게시판에서 게시물 제목에 등장하는 연습생의 이름을 세어보는 형식으로 순위를 매겨 보았었습니다. 시청자들의 인기투표로 선발되는 프로그램이니 만큼 시청자들의 입으로부터 많이 회자가 되면 그만큼 인기가 있을 것이란 가정하에 진행한 방식이였는데요. 오늘은 이를 확장하여 분석 모델링을 수행하겠습니다. 먼저 모델링을 통해 알고자 하는 바가 무엇인지를 정하는 것이 우선이겠습니다. 각 연습생의 인기가 게시물에서의 등장 횟수로 반영된다고 가정하였으므로 종속변수로 언급량(`mention`)을 설정하겠습니다.   

&nbsp;일간을 기준으로 그룹핑하여 각 연습생별 언급량 및 댓글수, 조회수, 추천수를 `total`이란 변수에 저장하겠습니다. 
```{r, cache=TRUE, message=FALSE, warning=FALSE}
temp <- c()
total <- c()
for(i in seq(1, length(boylist2))){
    # print(i)
    temp <- pxdata %>%
        filter(str_detect(p_title, boylist2[i])) %>%
        group_by(p_ymd) %>%
        summarise(sum_mention   = n(),
                  sum_comment   = sum(p_comment_num, na.rm = T),
                  sum_count     = sum(p_count),
                  sum_recommend = sum(p_recommend)) %>%
        mutate(boy = boylist[i])

    total <- rbind(total, temp)
}

total %>% glimpse()
DT::datatable(total)
```



































































<!--chapter:end:06-producex6.Rmd-->

# 다중회귀분석 
```{r, cache=TRUE, include = FALSE} 
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
library(plotly)
library(dlookr)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
boylist <- readLines('C:/Users/JDW/Desktop/PROJECT/PRODUCEX/final_boylist.txt')
boylist2 <- str_sub(boylist, -2, -1)
pxdata <- readRDS(str_glue('{dir}/pxdata.rds'))
temp <- c()
total <- c()
for(i in seq(1, length(boylist2))){
    # print(i)
    temp <- pxdata %>%
        filter(str_detect(p_title, boylist2[i])) %>%
        group_by(p_ymd) %>%
        summarise(sum_mention   = n(),
                  sum_comment   = sum(p_comment_num, na.rm = T),
                  sum_count     = sum(p_count),
                  sum_recommend = sum(p_recommend)) %>%
        mutate(boy = boylist[i])

    total <- rbind(total, temp)
}
```

## 데이터 분할
&nbsp;언급량(sum_mention)을 종속변수로 하는 다중회귀모델을 생성하고, 모델이 추정하는 예측치를 바탕으로 순위 매겨보겠습니다. 여기서는 전체 데이터 중 마지막 방송이 방영된 날의 데이터를 테스트 데이터로, 그 이전의 데이터를 모델의 학습데이터로 분할해 주겠습니다.  
```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)

# train & test 
total_train <- total %>% filter(p_ymd != '2019-07-19') # 마지막날 이전 데이터
total_test <-  total %>% filter(p_ymd == '2019-07-19') # 마지막날 데이터
```

&nbsp;그런 다음 댓글, 조회수, 추천수를 독립변수로 하여 언급량을 추정하는 다중회귀모델을 생성합니다. 
```{r}
total_lm <- lm(sum_mention ~ sum_count + sum_recommend + sum_comment + boy, data = total_train)
```

## 모델 검정 
&nbsp; 생성한 회귀모델이 적절한 모델인지를 검정하는 과정이 필요로 합니다. 회귀분석이 지닌 기본적인 가정인 정규성, 선형성, 독립성, 등분산성을 검정하는 과정을 거쳐 모델이 적절한지를 파악하는 과정을 수행해 보도록 합니다. 생성한 모델을 `plot()`함수를 사용하여 잔차시각화를 진행합니다.   
```{r}
par(mfrow = c(2, 2))
total_lm %>% plot()
par(mfrow = c(1, 1))
```

### 정규성 
&nbsp;선형회귀에서는 오차항이 정규분포를 따라야합니다. 그러므로 오차에 속한 잔차 역시 정규분포를 따라야 하는 가정을 따라야 합니다. 만약 잔차들이 정규성을 따른다면 Q-Q Plot상의 점들이 45도 각도의 직선에 밀접합니다.   
```{r, message=FALSE, warning=FALSE}
library(car)
total_lm %>% qqPlot()
```

&nbsp;육안으로 보아도 정규성에 위배되는 것을 확인할 수 있습니다. 

&nbsp;한편 `shapiro.test()`함수를 사용하면 더 정확하게 정규성을 검정할 수 있습니다. 잔차를 대상으로 Shapiro test 를 진행, p값이 기각역보다 크다면 잔차가 정규성을 띈다고 해석합니다.   
```{r}
shapiro.test(total_lm$residuals)
```

### 선형성 
&nbsp;독립변수는 종속변수와의 관계에서 선형성을 띄어야 하는 가정을 충족해야 합니다. 선형성은 회귀 모델에서 모델의 통계적 유의성 검정을 통해 추측할 수 있습니다. 만약 모델이 선형성을 충족한다면 모델에 대한 p값이 유의하게 나올 것입니다. 
```{r}
total_lm %>% summary()
```

&nbsp;`car`패키지에 있는 `crPlots()` 함수를 통해 개별 독립변수에 대한 선형성을 확인할 수 있습니다. 만약 plot에서 비선형성이 관찰된다면 이는 해당 변수가 선형성을 충족하지 못한것으로 볼 수 있습니다.   
```{r}
total_lm %>% crPlots()
```

### 독립성 
&nbsp;독립성 가정은 크게 세가지를 충족하여야 합니다. 첫째 모델의 예측값과 잔차간의 독립성. 둘째 독립변수와 잔차간의 독립성. 셋째 잔차의 자기상관성. 먼저 예측값과 잔차간의 독립성은 앞서 보았던 잔차그래프중 첫번째 그래프에서 확인할 수 있습니다.   
```{r}
total_lm %>% plot(which = 1)
```

&nbsp;생성된 그래프를 보면 이상치의 영향으로 인해 정확한 판단은 어렵지만 잔차가 무작위적으로 퍼져있는것이 아닌 특정 부분에 쏠려 있는것으로 보여 집니다. 만약 잔차에 패턴이 보인다면 이는 곧 모델이 패턴에 해당하는 규칙성을 누락했단 의미로 해석될 수 있으며 모델에 추가해야할 요소가 남아있음을 의미합니다.   

&nbsp;독립변수와 잔차간의 독립성은 상관계수 및 분포도로 판단할 수 있습니다. 모델에서 사용된 독립변인과 잔차를 묶어 `GGally::ggpairs()` 함수를 통해 확인해 보도록 하겠습니다.   
```{r, message=FALSE, warning=FALSE}
total_train %>% 
    select(sum_count, sum_recommend, sum_comment) %>% 
    mutate(residual = total_lm$residuals) %>% 
    GGally::ggpairs()
```

&nbsp;생성된 그래프를 보면 가운데를 기준으로 좌하단에는 변수간 산점도, 우상단에는 상관계수가 작성되어 있는 것을 확인할 수 있습니다. 여기에서 잔차(residual)와 각 독립변수(sum_count, sum_comment, sum_recommend)들 간의 상관계수는 0에 상회하는 것으로 거의 독립적인 것을 확인 할 수 있습니다. 그러나 각 독립변수들 간에 상관성이 높게 띄는것으로 보아 다중공선성이 크게 의심스러운 상황입니다.    

&nbsp;마지막으로 잔차의 자기상관성은  `car` 패키지에 있는 `durbinWatsonTest()` 함수를 통해 진행할 수 있습니다. 더빈왓슨 테스트의 검정통계량 D-W Statistic 값은 0 ~ 4의 값을 가지며 0으로 가까울 수록 (잔차의) 양의 상관관계를, 4에 가까울수록 음의 상관관계를 가집니다. 2는 독립적인 것을 의미합니다. 여기서의 p_value는 자기상관성에 대한 것인데 기각역보다 작다면 자기상관관계가 있다고 해석합니다.   

```{r}
total_lm %>% durbinWatsonTest()
```

&nbsp;더빈왓슨 테스트의 결과 잔차에는 어느정도 자기상관성이 존재하여 독립성을 충족하지 못한것으로 보입니다. 

### 등분산성 
&nbsp;잔차의 분산은 예측값과 관계없이 고루 퍼져있어야 합니다. 이는 표준화된 잔차그래프에서 확인할 수 있으며 0 수평선을 기준으로 랜덤한 형태로 분포가 되어 있는 모습이 이상적인 등분산성의 형태입니다. 
```{r}
total_lm %>% plot(which = 3)
```

&nbsp;생성된 그래프를 살펴보니 그래프의 특정 부위값에 몰려 있으며, 붉은색 추세선 역시 수평보다 위로 치우쳐져 있어 등분산성 가정에는 못미치는 것으로 판단됩니다. 등분산성 검정을 위한 통계적 검정법에는 `ncvTest()` 함수를 사용하는 방법이 있습니다.

```{r}
total_lm %>% ncvTest()
```

&nbsp;`ncvTest()`의 수행으로 나오는 p_value는 모델의 등분산성에 대한 검정 결과입니다. 여기서의 귀무가설은 모델이 등분산성을 따른다이며, 대립가설로는 등분산성을 따르지 않는것으로 보여짐 입니다. p값이 낮게 나온것으로 보아 등분산성의 검정역시 통과하지 못한것으로 보입니다. 

### 다중공선성 
&nbsp; 여러 변수들의 조합을 통해 만드는 다중회귀모델은 각 독립변수들의 독립성을 요구합니다. 만약 독립변수간에 강한 상관성이 존재한다면 이는 모델의 설명력에 왜곡을 불러올 것입니다. 다중회귀모델에서 독립변수에 대한 회귀계수는 다른 변인들이 0이라는 가정 하에 종속변수와 해당 독립변수 간의 선형성을  계산하는데 만약 독립변수끼리의 상관성이 존재한다면 상관성이 존재하는 변수들이 종속변수를 설명하는데 사용되는 분산이 중복되는 부분이 생겨 이는 곧 모델의 예측 성능 하락을 야기하고, 회귀식을 해석하는데 있어서 오류를 범하게 만드는 요인이 될 것입니다. 

&nbsp;다중공선성을 계산하는 방법으로는 `car`패키지의 `vif()`(분산팽창지수)함수를 사용하는 방법이 있습니다. 변수간의 상관성을 계산하는 vif()함수는 통계값이 일반적으로 4미만일시 문제없다고 판단하고, 10을 넘어가면 다중공선성 문제가 있다고 판단합니다.

```{r}
total_lm %>% vif()
```

&nbsp;다중공선성을 계산한 결과 연습생 변수만을 제외한 모든 변수에서 다중공선성이 존재하는것을 볼 수 있습니다. 

## 결과 
&nbsp;모델 검정 결과 다중회귀분석은 적절한 방법이 아닌것으로 판단할 수 있습니다. 선형회귀모델이 가진 가정을 검정한 결과 선형성의 조건을 제외한 나머지 정규성, 독립성, 등분상성의 조건을 충족하지 못하였으며 더 나아가 다중회귀모델에서 가지는 다중공선성의 문제역시 보유하고 있는 것을 볼 수 있었습니다. 어찌보면 당연한 것이 이번 모델링에서 사용한 변수들은 각각 게시물에 대한 조회수, 댓글수, 추천수인데 상식적으로 생각해봐도 조회수가 높은 게시물은 댓글과 추천을 많이 가질 확률이 높을 것입니다. 각 지표가 높게 나온 이유는 무엇보다 게시물의 **내용**이라는 공통된 요인이 유저들의 이목을 집중시켰을 테니까요. 그리고 무엇보다도 데이터가 가진 시계열적 요소를 배재한체 다중회귀분석을 진행한 것에 대한 문제점도 있었습니다. 시계열 데이터가 지닌 특징중에 하나인 자기상관성의 영향력도 무시하지 못할 요인인데 말이죠.   

```{r}
library(forecast)
ggAcf(total_lm$residuals)
```

&nbsp;`ggAcf()`는 ACF(Auto Correlation Function)(자기상관함수)를 계산하여 시각화한 함수로 과거 특정 시점과의 자기상관성을 계산하여 그래프로 표현하는 함수입니다. 푸른색 점선을 넘어가는 직선은 해당시점(lag)과의 상관성이 존재한다는 의미인데(시점의 자기상관성이 통계적으로 유의하다) 여기서 회귀모델의 잔차는 다수의 시점에서 자기상관성이 관측되는 것을 볼 수 있습니다. 이럴경우 일반적인 회귀모델보다 시계열분석이 더 적합할 수 있습니다.   

<!--chapter:end:07-producex7.Rmd-->

# 시계열 분석1
```{r, cache=TRUE, include = FALSE} 
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(data.table)
library(kableExtra)
library(plotly)
library(dlookr)
dir <- 'C:/Users/JDW/Desktop/PROJECT/PRODUCEX/CRAWLING DATA/2020ver'
boylist <- readLines('C:/Users/JDW/Desktop/PROJECT/PRODUCEX/final_boylist.txt')
boylist2 <- str_sub(boylist, -2, -1)
pxdata <- readRDS(str_glue('{dir}/pxdata.rds'))
temp <- c()
total <- c()
for(i in seq(1, length(boylist2))){
    # print(i)
    temp <- pxdata %>%
        filter(str_detect(p_title, boylist2[i])) %>%
        group_by(p_ymd) %>%
        summarise(sum_mention   = n(),
                  sum_comment   = sum(p_comment_num, na.rm = T),
                  sum_count     = sum(p_count),
                  sum_recommend = sum(p_recommend)) %>%
        mutate(boy = boylist[i])

    total <- rbind(total, temp)
}
```

&nbsp;기후나 주가지수와 같이 시간에 따라 관찰된 값들을 분석하는 경우 시계열분석 기법을 사용합니다. 과거의 값들을 토대로 미래의 값을 추정하거나 패턴들의 특징을 파악하기 위해 분석하는 기법입니다. 이전에 일간별로 수집한 데이터들을 전처리하여 연습생별 언급량을 계산하는 과정을 진행하였었는데 오늘은 이 데이터를 활용, 각 연습생별 적절한 모델을 찾고 해당 모델을 토대로 예측값을 도출하여 이를 비교하는 과정을 진행하겠습니다.   

## `ts`객체 
&nbsp;time-series의 약자인 `ts`객체는 이름에 나와있는 것처럼 시계열분석을 위해 사용되는 객체 중 하나입니다. 시간의 흐름에 따라 연속적인 속성을 지닌 변수에 `ts()`함수를 적용하여 생성할 수 있으며, 시계열에 존재하는 주기를 `frequency` 옵션을 사용하여 지정할 수 있는것이 특징입니다. 이전장에서 사용한 `total`변수를 사용하여 연습생들의 언급량의 총 합을 계산하여 이를 ts객체로 생성해 보겠습니다. 
```{r, message=FALSE, warning=FALSE}
library(dplyr)

ts_mention <- total %>% 
    group_by(p_ymd) %>% 
    summarise(sum_mention = sum_mention %>% sum()) %>% 
    ts(frequency = 7)

ts_mention
```

## 모델링 
### 시계열 회귀 모델
&nbsp;`forecast`패키지에 포함되어 있는 `tslm()` 함수는 시계열 회귀분석을 하는데 용이한 함수입니다. 일반적으로 `lm()`함수와 동일한 기능을 수행하지만 시계열 데이터가 보유하고 있는 계절성과 추세를 자동으로 계산하여 각각 `season`, `trend` 변수로 치환하고, 이를 회귀분석에 사용할 수 있도록 해줍니다. 
```{r, message=FALSE, warning=FALSE}
library(forecast)

# tslm 모델 생성 
mod_tslm <- tslm(sum_mention ~ trend + season, data = ts_mention)

# 모델 결과 
mod_tslm %>% summary()
```

&nbsp;생성된 모델의 결과를 살펴보면 자동으로 추세변수와 계절성 변수를 계산하여 이를통해 회귀식을 생성한 것을 볼 수 있습니다. 이렇게 생성된 모델을 `forecast()`함수를 통해 미래의 예측값을 도출해 낼 수 있습니다. 
```{r}
# 예측값 도출 
mod_tslm_pred <- mod_tslm %>% forecast(h = 7)
mod_tslm_pred
```

&nbsp;모델을 통한 예측값의 점추정 값과 신뢰구간을 계산해 줌을 볼 수 있습니다. 이렇게 계산된 예측값을 시각화하여 볼 수 있습니다. 
```{r}
# 예측값 시각화 
mod_tslm_pred %>% plot()
```

&nbsp;최종적으로 모델을 사용하기 이전에 모델의 성능을 측정하여 해당 모델이 다른 모델에 비해 성능적으로 우위가 있는지를 판단할 수 있습니다. 모델의 성능을 측정하는 방법에는 다양한 방법들이 존재합니다. 함수 `accuracy()`를 사용하면 주요 성능을 계산하여 보여줌으로서 모델의 성능을 파악하는데 용이합니다. 
```{r}
# 모델 정확성 
mod_tslm_pred %>% accuracy()
```

### ETS 
&nbsp;지수평활법(Exponential Smoothing)은 과거 시점의 값들을 지수적으로 감쇠시키는 가중치를 부여, 그 과정에서 시계열 데이터가 지니고 있는 추세적 특징과 계절성을 함께 사용하여 미래값을 추정하는 방식입니다. `ets()`함수를 통해 사용할 수 있습니다.   

```{r}
# ETS 모델 생성 
mod_ets <- ets(ts_mention[, 'sum_mention'])

mod_ets

# ETS 모델 예측값
mod_ets_pred <- mod_ets %>% forecast(h = 7)

# ETS 모델 예측값 시각화 
mod_ets_pred %>% plot()

# ETS 모델 성능 
mod_ets_pred %>% accuracy()
```

### ARIMA
&nbsp;시계열 데이터의 자기회귀성을 통해 미래값을 추정하는 arima 모델을 사용하여 미래값을 추정할 수 있습니다. arima 모델은 평균과 분산이 일정한 정상성의 성격을 가진 시계열 데이터를 자기회귀모델(Auto-Regressive model)과 이동평균모델(Moving Average model)을 결합한 모델로서 각각 특정 과거시점까지의 계수의 자기상관성과 오차의 자기상관성을 하나의 모델로서 구현한 것입니다. 본래 arima 모델을 구하기 위해서는 먼저 차분을 통한 시계열의 정상성 확보 이후 ACF와 PACF를 통한 적절한 AR 차수와 MA 차수를 구하는 과정이 필요하지만 R에서 제공하는 `auto.arima()`함수는 (AICc값의 최소로 하는 모델을 찾아) 최적의 arima 모델을 찾아 반환하여 줍니다. 
```{r, cache=TRUE}
# arima 모델 생성 
mod_arima <- auto.arima(ts_mention[, 'sum_mention'], stepwise = FALSE)

mod_arima

# arima 모델 예측값
mod_arima_pred <- mod_arima %>% forecast(h = 7)

# arima 모델 예측값 시각화 
mod_arima_pred %>% plot()

# arima 모델 성능 
mod_arima_pred %>% accuracy()
```


## 모델 평가 
&nbsp; `accuracy()`함수를 통해 계산한 모델들의 성능을 대조해 봄으로서 각 모델들의 성능을 한눈에 파악하고, 최적의 퍼포먼스를 보여주는 모델을 파악하여 최종 사용 모델로 선정할 수 있습니다. 생성한 모델들의 성능을 하나의 데이터 프레임으로 묶어 지표 기준으로 재정렬하는 과정을 진행합니다. 
```{r}
# 모델별 정확도 변수 생성  
mod_tslm_accuracy  <- mod_tslm %>% accuracy()
mod_ets_accuracy   <- mod_ets %>% accuracy()
mod_arima_accuracy <- mod_arima %>% accuracy()

# 모델 정확도 이름 지정
dimnames(mod_tslm_accuracy)[[1]]  <- 'mod_tslm'
dimnames(mod_ets_accuracy)[[1]]   <- 'mod_ets'
dimnames(mod_arima_accuracy)[[1]] <- 'mod_arima'

# RMSE 기준 정렬 
rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %>% 
    as.data.frame() %>% 
    arrange(RMSE)

# MAPE 기준 정렬 
rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %>% 
    as.data.frame() %>% 
    arrange(MAPE)

# ACF1(1시차 자기상관성) 기준 정렬 
rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %>% 
    as.data.frame() %>% 
    arrange(ACF1)
```

&nbsp;거의 모든 지표에서 arima 모델이 우위에 있는것으로 나오나 RMSE에서만은 ets 모델이 근소하게 우위에 있는것을 확인할 수 있습니다. 

## 시계열 교차 검증 
```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width = '100%', fig.align='center'}
knitr::include_graphics('./img_source/producex8/tscv.png')
```

&nbsp;단일 데이터에 대한 모델링은 모델이 데이터의 특성을 지나치게 학습하여 일반화된 예측에서 성능이 되려 떨어지게 되는 과적합의 위험성이 있습니다. 모델의 과적합을 방지하기 위해 데이터의 부분추출을 통한 학습을 여러번 수행하고, 각 학습마다의 성능을 측정하여 그 성능값을 평균내는 방식의 교차검증을 통해 과적합의 위험성을 방지할 수 있습니다.   

&nbsp;시계열 데이터에서의 교차검정은 `tsCV()`함수를 통해 수행할 수 있습니다. `tsCV()`함수는 특정 과거시점 까지의 데이터를 학습하고 누적 순차적으로 최신 데이터까지의 학습을 수행하는데 output으로 모델의 잔차를 반환하여 줍니다. 해당 잔차를 통해 각 모델별 성능을 계산하여 비교를 진행, 최적의 모델을 선택하여 사용할 수 있습니다. 

### 교차검증 함수 생성 
&nbsp; `tsCV()`의 인수로 시계열 모델링을 수행할 함수를 지정하는 과정이 필요합니다. 시계열 교차검증에 적합한 모델 함수를 생성하도록 하겠습니다. 
```{r, message=FALSE, warning=FALSE, cache=TRUE}
# 시계열 교차검증용 모델 생성 
forecast_arima <- function(x, h){
    auto.arima(x, stepwise = FALSE) %>% forecast(h = h)
}
forecast_tslm <- function(x, h){
    tslm(x ~ trend + season, data = x) %>% forecast(h = h)
}
forecast_ets <- function(x, h){
    ets(x) %>% forecast(h = h)
}

# 교차검증 잔차 
tslm_cv_residual  <- tsCV(ts_mention[, 'sum_mention'], forecast_tslm, h = 1)
ets_cv_residual   <- tsCV(ts_mention[, 'sum_mention'], forecast_ets, h = 1)
arima_cv_residual <- tsCV(ts_mention[, 'sum_mention'], forecast_arima, h = 1)

# 모델 평가 매트릭 함수 생성(RMSE)
RMSE <- function(res){
    mean(res^2, na.rm = TRUE)^0.5
}

data.frame(
    tslm  = tslm_cv_residual %>% RMSE(),
    ets   = ets_cv_residual %>% RMSE(), 
    arima = arima_cv_residual %>% RMSE()
)
```

&nbsp;모델별 교차검증 결과로 나온 잔차에 RMSE를 기준으로 계산한 결과 시계열 회귀 모델(tslm)의 성능이 상대적으로 우수한 것으로 판별이 되었습니다. 

### 최종 모델링
&nbsp;교차검증 모델 평가를 통해 시계열 회귀 모델을 사용하는 것이 괜찮다고 나왔으므로 이전에 생성한 시계열 회귀 모델을 최종 모델로 선정하겠습니다. 
```{r}
mod_tslm <- tslm(sum_mention ~ trend + season, data = ts_mention)
```

### 잔차 검정 
&nbsp;마지막으로 시계열 모델의 잔차가 백색잡음을 띄는지를 검정하도록 하겠습니다. 만약 잔차에 패턴 혹은 상관성이 존재할 경우 모델이 이는 회귀모델의 독립성 가정에 위배되므로 잘못된 모델이라고 할 수 있습니다.   
```{r}
mod_tslm %>% checkresiduals()
```
&nbsp; 생성된 그래프의 잔차분포는 조금은 치우쳐 있지만 정규분포의 형태와 흡사해 보이고 acf역시 크게 이상은 없어보입니다. `checkresiduals()`함수는 모델이 회귀분석 모델이면 Breusch-Godfrey test를, 그렇지 않으면 Ljung-Box test를 진행합니다. 두 검정법 모두 귀무가설로 잔차의 상관성이 통계적으로 유의성이 존재하지 않는다 정의하고 있습니다.(백색잡음이라 보여짐) `checkresiduals()`함수의 결과로 p_value > 0.05 인 것을 보아 모델의 잔차에는 이상이 없어 보입니다.   

### 예측 
&nbsp;잔차검정까지 마친 모델을 대상으로 미래 시점의 값을 추정해 볼 수 있습니다. 앞서 사용한 `forecast()`함수를 통해 시계열 회귀 모델의 미래 추정값을 계산하고, 이에대한 신뢰구간을 계산하여 파악할 수 있습니다.    
```{r}
mod_tslm %>% forecast(h = 7)
```

&nbsp;모델을 생성하는데 사용된 총 언급량 데이터와 이를 시계열 회귀모델에 적합한 값 그리고 회귀모델의 예측값까지 시각화하여 확인할 수 있습니다. `ggplot2` 문법을 따르는 `autoplot()`함수를 통해 시계열 시각화를 수월하게 할 수 있습니다.   
```{r}
library(ggplot2)

ts_mention[, 'sum_mention'] %>% 
    autoplot(series = 'Original') +  
    autolayer(fitted(mod_tslm), series = 'tslm_fitted') + 
    autolayer(forecast(mod_tslm), h = 7, series = 'tslm_forecast') + 
    scale_color_manual(values = c('Original' = 'black', 'tslm_fitted' = 'red', 'tslm_forecast' = 'blue'),
                       breaks = c('Original', 'tslm_fitted', 'tslm_forecast'))
```

&nbsp;위의 과정을 통해 검정선의 실제 데이터(총 언급량)과 붉은선의 모델에 적합한 값을 비교하여 볼 수 있고, 파란 음영처리된 신뢰구간을 포함한 미래 예측값을 하나의 그래프로 표현하여 한 눈에 볼 수 있습니다.   

# 시계열 분석2
&nbsp;지금까지 연습생들의 언급량을 총 합산한 데이터를 토대로 시계열 예측 과정을 진행하였습니다. 이 과정을 개별 연습생에 대한 언급량 데이터에 적용하여 각각의 연습생들에 적법한 모델을 찾고 그 모델을 토대로 바로 다음 시점의 언급량을 추정, 이를 대조하여 언습생들의 인기를 추측해 보겠습니다.   

## 연습생별 모델링 함수 생성
```{r, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# 연습생별 최적 성능 모델 생성 함수 
boy_model <- function(total, final_boy){
    # 연습생 언급량 필터링 & ts 객체 변환 
    boy_ts <- total %>% 
        filter(boy == final_boy) %>% 
        ts(frequency = 7)
    
    # 시계열 교차검증용 모델 지정 
    forecast_arima <- function(x, h){
        auto.arima(x, stepwise = FALSE) %>% forecast(h = h)
    }
    forecast_tslm <- function(x, h){
        tslm(x ~ trend + season, data = x) %>% forecast(h = h)
    }
    forecast_ets <- function(x, h){
        ets(x) %>% forecast(h = h)
    }
    
    # 모델 평가 매트릭 함수 지정(RMSE)
    RMSE <- function(y){
        mean(y^2, na.rm=TRUE)^0.5
    }
    
    # 시계열 교차검증 
    tslm_cv_residual  <- tsCV(boy_ts[, 'sum_mention'], forecast_tslm, h = 1)
    ets_cv_residual   <- tsCV(boy_ts[, 'sum_mention'], forecast_ets, h = 1)
    arima_cv_residual <- tsCV(boy_ts[, 'sum_mention'], forecast_arima, h = 1)
    
    # 최적 성능순 모델 이름 추출   
    models <- data.frame(model = c('tslm', 'ets', 'arima'), 
                         score = c(RMSE(tslm_cv_residual), RMSE(ets_cv_residual), RMSE(arima_cv_residual))) %>% 
        arrange(score) %>% 
        .$model
    
    # 모델 적용 함수 
    select_model <- function(type){
        
        if(type == 'tslm'){
            final_model <- tslm(sum_mention ~ trend + season, data = boy_ts)
        }
        
        if(type == 'ets'){
            final_model <- ets(boy_ts[, 'sum_mention']) 
        }
        
        if(type == 'arima'){
            final_model <- auto.arima(boy_ts[, 'sum_mention'], stepwise = FALSE)
        }
        
        return(final_model)
    }
    
    # 최적 모델 적용 
    for(model in models){
        # print(model)
        final_model <- select_model(type = model)
        
        # 잔차검정 
        if(checkresiduals(final_model, plot = FALSE)$p.value > 0.05){
            # 테스트 통과시 for문 종료
            break
        }
    }
    
    # 모든 모델이 잔차검정 통과 못할 시 
    # 차선책으로 가장 좋은 성능을 내는 첫번째 모델 선택
    if(checkresiduals(final_model, plot = FALSE)$p.value <= 0.05 && model == models[3]){
        
        model <- models[1]
        
        final_model <- select_model(type = model)
    }
    
    # 최적 모델, 사용된 모델명 반환 
    boy_model <- list(
        model     = final_model, 
        use_model = model
    )
    
    return(boy_model)
}

final <- c()
final_boy <- c()
for(final_boy in boylist){
    print(final_boy)
    final[[final_boy]] <- boy_model(total, final_boy)
}

```

&nbsp;연습생 개개인의 상황에 맞는 우수한 성능 모델을 찾아 잔차검정까지 마친 최적의 모델을 찾아 반환하는 `boy_model()`함수를 사용하여 그 결과물을 `final` 객체에 저장하였습니다.   

## 사용 모델 확인 
&nbsp;연습생들에 적용된 최적의 모델이 무엇인지 확인하겠습니다.   
```{r}
final %>% 
    purrr::map(function(x){x$use_model}) %>% 
    do.call(rbind, .) %>% 
    as.data.frame() %>% 
    kableExtra::kable() %>% 
    stringr::str_remove('V1') %>%
    shiny::HTML()
```

&nbsp;연습생별 최적 모델을 찾는 함수에서 지정한 `use_model`변수는 개별 모델을 적용할 때 사용한 모델의 이름을 저장한 변수입니다. 이 변수만을 별도로 보니 연습생별로 모델을 적용하는데 있어서 대체로 arima 모델과 시계열 회귀모델이 선택되고 ets 모델은 상대적으로 덜 선택된 것을 볼 수 있습니다. 이처럼 언급량 데이터는 성격과 형태가 유사한 데이터 이지만 데이터가 지닌 시계열적 특징에 따라 적용된 모델이 상이한 것을 확인할 수 있었습니다. 

## 모델 시각화 
&nbsp;개개인의 데이터에 맞춘 모델을 이전장에서 했던 유사한 시각화 방식으로 파악할 수 있습니다. 생성된 모델과 실제 데이터를 모델에 적합한 값 그리고 모델이 예측한 값을 연습생별로 시각화하여 살펴보도록 하겠습니다. 

```{r, cache = TRUE, warning=FALSE, message=FALSE}
# 모델 시각화 함수 생성  
library(tidyquant)

boy_plot <- function(boy){
    forecast(final[[boy]]$model, h = 7) %>% 
        autoplot() + 
        autolayer(fitted(final[[1]]$model), series = 'fitted', color = 'red') + 
        scale_x_continuous(breaks = seq(1, 9), 
                           labels = str_glue("{(seq(1, 7) + 4) %>% append(c('final', 'predict'))}")) + 
        theme_tq() + 
        labs(subtitle = boy, x = 'episode', y = 'sum_mention') + 
        theme(plot.subtitle = element_text(hjust = 1, size = 12)) 
}

# 연습생별 모델 그래프 저장 
i = 0
final_plot <- c()
for(i in seq(1, 20)){
    final_plot[[i]] <- boy_plot(boylist[i])
}
```

```{r, eval=FALSE}
library(gridExtra)
do.call('grid.arrange', c(final_plot, ncol = 1))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# 시각화 
library(gridExtra)
do.call('grid.arrange', c(final_plot[1:3], ncol = 1))
do.call('grid.arrange', c(final_plot[4:6], ncol = 1))
do.call('grid.arrange', c(final_plot[7:9], ncol = 1))
do.call('grid.arrange', c(final_plot[10:12], ncol = 1))
do.call('grid.arrange', c(final_plot[13:15], ncol = 1))
do.call('grid.arrange', c(final_plot[16:18], ncol = 1))
do.call('grid.arrange', c(append(final_plot[19:20], list(ggplot() + theme_void())), ncol = 1))
```

&nbsp;방송이 방영된 회차에 발생한 실제 언급량을 검정선에, 생성된 모델에 실제 언급량을 반영한 모델값을 붉은색선, 그리고 방송이 끝난 후의 언급량을 모델이 예측한 값을 푸른색 신뢰구간과 함께 파란색선으로 표현하였습니다. 연습생별로 모델이 추정한 미래 값이 서로 상이한 것을 볼 수 있습니다.   

## 결론 
&nbsp;지금까지 적지 않은 과정을 통해 시계열 분석 절차를 진행 해 왔습니다. 모델에 사용된 데이터는 커뮤니티 게시판에서 시청자들 혹은 방송에 관심이 있는 유저들이 작성한 게시글의 제목으로, 이 제목 중 특정 연습생 인물의 이름 또는 별명을 일간별로 계산하여 이를 시계열 모델로 생성하였는데요. 이제 해당 개별 모델들이 추정한 방송이 끝난 한 시점 이후의 미래값을 비교하여 연습생들의 (추정 언급량)순위를 매겨 보겠습니다.    

&nbsp;모델을 생성하였으면 미래값을 추정하는 것은 그리 어려운 일이 아닙니다. 지금까지 자주 사용하였던 `forecast()`함수를 사용하여 개개인의 미래값을 도출하고 이를 하나의 데이터프레임으로 묶겠습니다. 

```{r}
library(purrr)

compare_pred <- final %>% 
    map(function(x){
        x$model %>% 
            forecast(h = 7) %>% 
            as.data.frame() %>% 
            map_df(mean)
    }) %>% 
    do.call(rbind, .)

compare_pred
```

&nbsp;예측은 모델이 바로 1 시점 이후를 예측하는 것이 아닌 시계열 데이터가 지니고 있는 주기적인 반복성인 계절성의 영향을 고려하여 모델의 7 예측 시점 까지를 구하고 이를 평균낸 값을 활용하도록 하겠습니다. 각 모델별로 7 시점 미래 값을 평균내어 예측 신뢰구간과 함께 점추정값을 하나의 객체에 저장하였습니다. 여기서 비교의 대상이 될 점추정값(Point Forecast)값을 기준으로 연습생들을 재정렬, 이를 순위매겨보도록 하겠습니다.   
```{r, message=FALSE, warning=FALSE}
model_rank <- compare_pred %>% 
    arrange(desc(`Point Forecast`)) %>% 
    mutate(rank = row_number(), 
           boy  = rownames(.)) %>% 
    select(rank, boy, `Point Forecast`)

library(kableExtra)

kable(model_rank, align = 'c') %>% 
    kable_styling(bootstrap_options = "striped", full_width = T, position = "center")
```

&nbsp;모델이 추정한 미래값을 기준으로 최종 11명을 뽑자면 **조승연**, **김우석**, **구정모**, **이은상**, **한승우**, **김민규**, **김요한**, **남도현**, **강민희**, **금동현**, **황윤성** 순으로 뽑을 수 있겠습니다.   

&nbsp;이전 5장에서 순위를 매겼던 방식인 방송 기간 중 연습생별 총 언급량 기준, 그리고 방송의 마지막 주차(11주차)를 기준으로 정렬한 언급량 순위랑 비교해보면 어떠한 차이가 있을지 비교해 보도록 하겠습니다. 

```{r, warning=FALSE, message=FALSE, cache=TRUE}
library(stringr)

temp_mention <- c()
episode_mention <- c()
for(i in seq(1, 20)){
    temp_mention <- pxdata %>%
        filter(str_detect(p_title, boylist2[i])) %>%
        group_by(p_episode) %>%
        summarise(mention =n()) %>%
        mutate(boy = boylist[i])
    
    episode_mention <- rbind(episode_mention, temp_mention)
}

week11_rank <- episode_mention %>% 
    filter(p_episode == 11) %>% 
    arrange(desc(mention)) %>% 
    mutate(week11_rank = row_number()) %>% 
    rename(week11_mention = mention) %>% 
    select(week11_rank, boy, week11_mention)

total_rank <- episode_mention %>% 
    group_by(boy) %>% 
    summarise(total_mention = sum(mention)) %>% 
    arrange(desc(total_mention)) %>% 
    mutate(total_rank = row_number()) %>% 
    select(total_rank, boy, total_mention)

all_rank <- model_rank %>% 
    rename(model_rank = rank) %>% 
    left_join(week11_rank, by = 'boy') %>%
    left_join(total_rank , by = 'boy') %>% 
    select(model_rank, week11_rank, total_rank, boy, `Point Forecast`, week11_mention, total_mention)

```

```{r, message=FALSE, warning=FALSE}
library(DT)

my_table <- function(dt){
    dt %>% datatable(rownames = F, 
                     options = list(dom = 't', 
                                    pageLength = 20, 
                                    columnDefs = list(list(className = 'dt-center', targets = 0:6)),
                                    # column name 사이즈 조절 
                                    headerCallback = DT::JS(
                                        "function(thead) {",
                                        "  $(thead).css('font-size', '0.8em');",
                                        "}"
                                    ) 
                     )
    ) %>% 
        formatRound("Point Forecast", 2) %>% 
        formatStyle(columns = colnames(.), fontSize = '70%') 
}

my_table(all_rank)

```

&nbsp;기준별로 순위는 상이하지만 상위권과 하위권이 대체로 유사하게 나타나는 것처럼 보입니다. 그렇다면 모델이 추정한 값의 순위, 11주차 기준 순위, 전체 언급량 순위 모두에서 데뷔 순위로 나타나는 연습생과 그렇지 않은 연습생은 어떠한지 보겠습니다. 

```{r}
# 모든 기준에 들어가는 연습생 
all_rank %>% 
    filter(model_rank  %in% seq(1, 11)) %>% 
    filter(week11_rank %in% seq(1, 11)) %>% 
    filter(total_rank  %in% seq(1, 11)) %>% 
    my_table()

```

&nbsp;모든 기준에서 최종 데뷔조로 나타나는 연습생은 각각 **조승연**, **김우석**, **구정모**, **이은상**, **한승우**, **김민규**, **김요한**, **남도현**이 좋은 수치를 내는 것을 볼 수 있습니다. 

```{r}
# 모든 기준에 들어가지 않는 연습생 
all_rank %>% 
    filter(!model_rank  %in% seq(1, 11)) %>% 
    filter(!week11_rank %in% seq(1, 11)) %>% 
    filter(!total_rank  %in% seq(1, 11)) %>% 
    my_table()
```

&nbsp;한편 **송유빈**, **차준호**, **토니**, **이한결**, **손동표**, **함원진**, **이세진** 연습생들은 모든 기준에서도 데뷔조에 들어가지 않는것으로 나오고 있습니다. 하지만 해당 결과를 실제 예측에 반영하기는 무리가 있는점이 있습니다. *신뢰구간*을 고려하지 않은 점추정 값의 비교는 자칫 치명적인 오류를 범할 수 있기 때문입니다. 예를들어 어느 두 사람의 추정값이 상대적으로 높게 나오더라도 신뢰구간이 겹치게 된다면 이는 실제 두사람의 결과가 얼마든지 바뀔 수 있기 때문입니다.  

```{r}
final[['송형준']]$model %>% 
    forecast(h = 7) %>% 
    autoplot(conf.int.fill = 'royalblue1', conf.int.alpha = 0.2) + 
    autolayer(final[['황윤성']]$model$data$sum_mention,    color = 'violetred4')  + 
    autolayer(final[['황윤성']]$model %>% forecast(h = 7), color = 'red',  alpha = 0.2) + 
    labs(title = "황윤성 - 송형준 95% 신뢰구간 비교")
```

&nbsp;그래프에 붉은색으로 음영처리된 부분은 모델이 데뷔조의 마지막 등수인 11등으로 예측한 **황윤성**의 95% 신뢰구간을 표시한 것이고, 푸른색 음영처리 부분은 12등으로 예측한 **송형준**의 신뢰구간을 의미합니다. 신뢰구간인 즉슨 실제 값이 신뢰구간에 속할 확률이 95%란 의미인데 이처럼 겹쳐있는 부분이 존재하면 특히 겹쳐있는 부분의 범위가 넓을수록 쉽사리 누가 우위에 있는지를 속단하기 어려운 의미입니다.   

&nbsp;또한 데이터의 출처를 생각해 보자면 특정 커뮤니티에서의 의견이기 때문이기 때문에 커뮤니티에 활동하는 유저의 *성향*에 따라 데이터가 편향이 될 가능성이 높습니다. 수집한 데이터의 출처가된 커뮤니티의 유저들이 전체 시청자들의 의견을 대변하는건 아니기 때문에 해당 모델링 결과를 통해 최종 예측을 하기엔 다소 무리가 있습니다.    

&nbsp;그렇다면 진행한 모델링의 결과는 의미가 없냐? 또 그렇진 않습니다. 분석의 대전제가 된 언급량이 많을수록 인기가 있을것이다란 것에 맞춘 모델링이기에 여기서의 값이 높게 나온 연습생은 실제로 인기가 높은 연습생일 확률이 높습니다. 또한 높은 확률로 데뷔조에 속할 가능성이 있습니다.       

&nbsp;실제로 모델의 예측치 순위에서 3위에 있는 **구정모** 연습생과 10위의 **금동현** 연습생은 제작진의 (조작된) 방송의 최종 순위에서는 탈락한 것으로 발표 되었지만 (재판 과정에서 드러난) 실제 순위에선 각각 6위, 8위를 기록하여 최종 데뷔조 였단 것이 밝혀졌었습니다. 모델의 결과를 전적으로 신뢰하긴 어렵지만 어떤 연습생이 인기가 있었는지 참고하기엔 좋은 자료인 것 같습니다. 


--- 

<br>
&nbsp;지금까지 데이터 수집부터 모델 예측까지 다양한 절차를 통해 분석을 진행하였습니다. 최종 투표에서 조작이 있었다는 의혹으로 인해 지난해 말 프로듀스 X 101은 의혹에 대한 재판이 진행되었었고, 재판의 결과로 실제로 제작진의 투표조작이 있었다는 발표가 있었습니다. 처음 이 분석을 기획한 당시에 시청자들의 의견이 담긴 텍스트를 분석하면 최종적으로 선발될 연습생이 누군지 알 수 있지 않을까란 생각과, 이를 실제 결과와 대조하면 유의미한 결과가 있지 않을까 싶어 진행하였지만 실상은 모든것이 제작진의 조작이였다는 발표를 듣게 되니 약간은 허탈하면서도 평소 프로그램을 즐겨보던 한명의 시청자로서 아쉬운 발표이기도 했었습니다. 재판 이후에 나온 관련 기사들을 읽다보니 지금껏 너무 순진하게 방송국놈들을 믿었던건 아닌지 싶은 생각이 들기도 하더군요 ^^; 재판으로 밝혀진 사실이 궁금하신 분들은 [판결문 전문](https://legalengine.co.kr/cases/50035495) 또는 잘 정리된 [기사](http://www.newdaily.co.kr/site/data/html/2021/01/22/2021012200179.html#livereGuideBtn)에서 확인 하실 수 있습니다. 이것으로 프로듀스 X 101 데뷔 예측 분석을 마치도록 하겠습니다. 






































<!--chapter:end:08-producex8.Rmd-->

