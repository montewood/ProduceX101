[
["index.html", "텍스트 분석을 통한 프로듀스X101 데뷔조 예측 Update", " 텍스트 분석을 통한 프로듀스X101 데뷔조 예측 JDW 2019-12-19 Update 업데이트 날짜 : 2021-01-27 업데이트 내역 : 1. 다중회귀분석 및 시계열 예측 모델 추가 2. 방송 이후 추가로 알려진 사실에 대한 내용 추가 3. 본문 중 잘못 서술하거나 미흡했던 내용 수정 "],
["prologue.html", "Chapter 1 Prologue", " Chapter 1 Prologue 사진출처 : 엠넷 조금은 시간이 지났지만 지난 2019년 여름 “프로듀스 X 101” 프로그램이 한참 방영했던 당시 진행했던 텍스트 분석입니다. 엠넷의 대표적인 방송중 하나인 프로듀스 시리즈는 매 시리즈마다 숱한 화제를 불러오며 인기를 끌었던 서바이벌 오디션 프로그램인데요. 그 중 이번에 분석한 “프로듀스 X 101”은 4번째 시리즈로서 101명의 연습생들이 방송에서 무대를 선보이고, 시청자들의 투표를 통해 최종 11명의 아이돌멤버를 선발한다는 컨셉의 방송입니다. 이 글을 쓰고 있는 시점인 2019년 11월 현재 프로듀스 시리즈는 제작진의 투표조작 논란에 휩싸여 시청자의 투표를 통해 선발한다는 컨셉이 무색해졌지만 그래도 분석을 통해 어느 연습생이 시청자들의 관심을 받았었는지 혹은, 누가 많은 이슈를 몰고 있었는지를 수치로 확인할 수 있었기에 나름 의미있는 분석이었다고 생각이 듭니다. 전체적인 구성은 다음과 같습니다. 1. 데이터수집 2. 데이터 전처리 및 취합 3. 시각화 4. 모델링 데이터 수집 단계에서는 온라인 커뮤니티에 올라오는 시청자들의 의견을 수집하였습니다. 방송 기간중 유저들이 활발히 활동을 하였던 사이트를 대상으로 웹 스크래핑 기법을 통해 수집을 진행. 데이터 전처리 및 취합에서는 일간별로 수집된 데이터를 확인하고, 이를 취합하여 분석에 용이한 형태로 전처리하는 과정을 담았습니다. 취합한 데이터를 바탕으로 특징적인 부분을 시각화를 통해 탐색해 보았으며, 최종적으로 다중회귀식을 활용한 예측모델을 생성하여 모델링을 통한 예측의 과정도 정리하였습니다. 그럼 이제 단계별로 차근차근 알아보겠습니다. "],
["데이터-수집.html", "Chapter 2 데이터 수집 2.1 웹 스크래핑", " Chapter 2 데이터 수집 데이터 분석을 위해 가장 먼저 진행한 것은 분석의 대상이 될 데이터를 확보 하는 일 입니다. 이번장에서 진행할 것은 데이터 수집에 관한 전반적인 것들 입니다. “프로듀스 X 101”은 당시 인기가 많은 프로그램이었기 때문에 다양한 웹 커뮤니티에서 방송에 대한 많은 의견들이 올라왔었습니다. 물론 이들 모두를 수집하여 분석하면 더욱 좋았겠지만 취미로 진행하였기에 커뮤니티 중 활발히 활성화가 되고 있던 한 곳을 선정하여 데이터 수집을 진행하였습니다. 웹 커뮤니티에 올라오는 글 해당 커뮤니티는 방송이 인기를 끌었던 시점에는 하루에 대략 4만건의 게시물 까지 올라왔었는데요. 한참 방송이 진행중이던 06/01 부터 마지막 생방송날인 07/19 까지의 데이터를 수집하였었습니다. 웹 데이터 수집을 위한 여러 방법이 있지만 R 에서 웹페이지를 수집할 때 보편적으로 사용하는 rvest 패키지를 주로 활용하여 스크래핑을 진행하였습니다. 주의사항! 크롤링 혹은 스크래핑을 통한 데이터 수집을 진행할 경우에는 웹사이트 소유권자가 제공하는 robot.txt 를 준수하며 진행해야 합니다. 비록 의무가 아닌 권고이지만 이를 무시하고 크롤링을 진행할 경우 윤리적 문제뿐만 아니라 심할 경우 현행법 위반 으로 법에 저촉되는 행위가 될 수 있습니다. 아래부터는 스크래핑 코드 입니다. 2.1 웹 스크래핑 # 저장 폴더 설정 ---- dataFolder &lt;- &#39;저장폴더경로&#39; setwd(dataFolder) # 사용 패키지 호출 ---- library(rvest) library(httr) library(dplyr) library(lubridate) library(stringr) 먼저 스크래핑한 데이터를 저장할 폴더와 필요한 패키지들을 호출합니다. # 주소설정 ---- basic_url &lt;- &#39;https://gall.dcinside.com/board/lists/?id=producex&amp;page=&#39; urls &lt;- NULL for(x in 0:999){ urls[x + 1] &lt;- paste0(basic_url, x + 1) } 웹페이지의 주소를 기반으로 스크래핑을 진행하기 때문에 정보를 가져올 웹페이지의 주소를 for문을 통해서 만들어 줍니다. 해당 코드를 돌리면 다음과 같은 결과값이 나옵니다. head(urls);tail(urls) ## [1] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=1&quot; ## [2] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=2&quot; ## [3] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=3&quot; ## [4] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=4&quot; ## [5] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=5&quot; ## [6] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=6&quot; ## [1] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=995&quot; ## [2] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=996&quot; ## [3] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=997&quot; ## [4] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=998&quot; ## [5] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=999&quot; ## [6] &quot;https://gall.dcinside.com/board/lists/?id=producex&amp;page=1000&quot; for문을 통해 1페이지부터 1000페이지까지 총 1000개의 웹페이지 주소가 생성되었네요. 만들어진 주소들을 기반으로 스크래핑을 진행합니다. 먼저 스크래핑 정보를 담을 빈객체들을 생성합니다. # 빈 객체 생성 ---- gallMain &lt;- NULL p_title &lt;- NULL p_comment_num &lt;- NULL p_time &lt;- NULL p_count &lt;- NULL p_recommend &lt;- NULL dc &lt;- NULL 본격적으로 for문을 통해 데이터를 페이지순으로 순차적으로 가져옵니다. # 스크래핑 ---- for(url in urls){ gallMain &lt;- GET(url, timeout(10)) %&gt;% read_html() %&gt;% html_nodes(&#39;.ub-content.us-post&#39;) p_title &lt;- sapply(seq(1, length(gallMain)), function(x){ gallMain[x] %&gt;% html_nodes(&#39;.gall_tit.ub-word&#39;) %&gt;% html_node(&#39;a&#39;) %&gt;% html_text() }) p_comment_num &lt;- sapply(seq(1, length(gallMain)), function(x){ gallMain[x] %&gt;% html_nodes(&#39;.gall_tit.ub-word&#39;) %&gt;% html_nodes(&#39;.reply_numbox&#39;) %&gt;% html_text() %&gt;% str_replace_all(., &#39;[[:punct:]]&#39;, &#39;&#39;) %&gt;% paste(., collapse = &#39;&#39;) }) p_time &lt;- sapply(seq(1, length(gallMain)), function(x){ gallMain[x] %&gt;% html_nodes(&#39;.gall_date&#39;) %&gt;% html_attr(&#39;title&#39;) }) p_count &lt;- sapply(seq(1, length(gallMain)), function(x){ gallMain[x] %&gt;% html_nodes(&#39;.gall_count&#39;) %&gt;% html_text() }) p_recommend &lt;- sapply(seq(1, length(gallMain)), function(x){ gallMain[x] %&gt;% html_nodes(&#39;.gall_recommend&#39;) %&gt;% html_text() }) } for문을 돌릴 시 맨 처음 만들었던 주소들 즉, urls 객체에 담긴 주소값을 받아서 서버에게 순차적으로 주소에 대한 정보를 요청하게 됩니다. 그렇게 응답받은 정보를 바탕으로 for문 내부에 있는 파싱코드를 수행하는게 되는데요. 각각의 객체에 해당하는 값들을(p_title, p_time…) 파싱합니다. for문 내 모든 과정을 수행하면 for문은 다음 주소를 요청하여 처음부터 다시 파싱을 진행하게 됩니다. # 데이터 프레임화 ---- dc &lt;- data.frame(p_title, p_comment_num, p_time, p_count, p_recommend) # 날짜조정 ---- dc$p_time &lt;- ymd_hms(dc$p_time) dc &lt;- dc[day(dc$p_time) == day(today()-1), ] for문을 통해 수집한 각각의 객체 데이터들을 dc 라는 이름의 데이터프레임에 담아주었습니다. 시간을 다루는 lubridate 패키지의 ymd_hms()함수를 이용하여 글 작성 시간을 의미하는 p_time 데이터를 시간 데이터로 변경해 줍니다. 코드는 taskscheduleR 패키지를 활용하여 매일 자정 무렵 자동으로 돌아가게끔 설정 했었는데요. 데이터를 매일 수집하는 것이다 보니 오직 전날에 작성된 글들만을 저장하기 위해서 dc &lt;- dc[day(dc$p_time) == day(today()-1), ] 필터링 코드를 만들었습니다. 코드를 짧막하게 설명하자면 글 작성 시간을 의미하는 dc$p_time 이 수집하는 날 바로 하루 전 today() - 1 의 값과 동일한 값만을 dc객체로 새로이 담아낸 것입니다. p_title p_comment_num p_time p_count p_recommend 41684 ??? 2019-06-01 00:00:02 5 0 41685 시즌4 비센이 잇긴 하냐 1 2019-06-01 00:00:01 11 1 41686 아아아아앙 민희야어아아아앙 2019-06-01 00:00:01 4 0 41687 아악 유리옵ㅠㅠㅠㅠㅠㅠ 1 2019-06-01 00:00:00 40 0 41688 김민규 그와중에 또 핑크입은거 실화냐 1 2019-06-01 00:00:00 36 0 41689 진짜 한남들 자적자 어뜩하냐 2019-06-01 00:00:00 27 1 스크래핑을 마친 데이터의 구조 # 파일저장 ---- write.csv(dc, paste0(ymd(today()-1), &quot;.rds&quot;)) 마지막으로 필터링까지 완료된 데이터를 rds파일로 저장합니다. "],
["데이터-전처리.html", "Chapter 3 데이터 전처리 3.1 데이터 취합 3.2 Feature Engineering", " Chapter 3 데이터 전처리 이번 파트는 데이터 전처리 과정을 다룹니다. 스크래핑한 데이터들은 사용하기 위해서는 적합한 형태로 변환을 해야 하는 과정이 필요합니다. 파일들을 R로 불러들이겠습니다. 3.1 데이터 취합 # 사용 패키지 호출 ---- library(dplyr) library(ggplot2) library(lubridate) library(stringr) library(data.table) # for문을 활용한 데이터 불러오기 및 취합 ---- filelist &lt;- list.files(dir) # dir : &quot;저장된 데이터의 폴더 경로&quot; pxdata &lt;- data.frame() temp &lt;- NULL for(file in filelist){ if(str_sub(file, -3, -1) == &#39;rds&#39;){ temp &lt;- readRDS(paste(dir, file, sep = &#39;/&#39;)) temp &lt;- temp %&gt;% select(p_title, # 제목 p_comment_num, # 댓글 수 p_time, # 글 작성 시간 p_count, # 조회수 p_recommend) # 추천수 pxdata &lt;- rbind(pxdata, temp) rm(temp) }else{ next } } 일간별로 수집했던 데이터들을 불러와 pxdata라는 데이터프레임에 취합 하였습니다. 이를 활용하여 분석을 진행할 예정입니다. 3.2 Feature Engineering 데이터 수집 과정을 통해 p_title, p_time, p_count, p_recommend 의 변수를 생성하였습니다. 그 중 p_time 변수는 게시글의 작성된 시간이 초단위까지 기록된 변수인데, 해당 변수를 활용해서 날짜, 요일과 같은 좀 더 세분화된 시간변수를 생성하도록 하겠습니다. pxdata &lt;- pxdata %&gt;% mutate(p_ymd = as.Date(p_time), # 년-월-일 p_month = as.factor(month(p_time)), # 월 p_day = as.factor(day(p_time)), # 일 p_hour = as.factor(hour(p_time)), # 시간 p_wday = as.factor(lubridate::wday(as.Date(p_time), label = T))) # 요일 “프로듀스 X 101”은 매주 금요일 밤 11시에 시작하여 다음날 토요일 AM 12:30즈음 끝이 났었는데요. 데이터가 에피소드별로(매 주 방송되는 1주 간격으로) 어떻게 그리고 얼마나 변화했는지를 파악하기 위해 lubridate패키지의 week()함수를 사용하여 게시판의 글이 몇 화의 에피소드때 작성되었는지를 알리는 변수인 p_episode 변수를 생성하도록 하겠습니다. 매 화 방송이 끝나는 토요일부터 그 다음주 금요일까지의 기간을 하나의 에피소드 기간으로 취급하여 변수를 생성하였습니다. 처음 데이터를 수집하기 시작한 날짜인 2019-06-01은 토요일로 전날 5화가 방영되던 날 이였습니다. 이 정보를 토대로 p_episode 변수를 생성하도록 하겠습니다. 새로 생성된 시간과 관련된 변수들은 범주형 속성을 지니고 있으므로 as.factor()함수를 사용하여 범주형 값으로 변환했습니다. pxdata &lt;- pxdata %&gt;% mutate(p_episode = week(p_ymd - 5) - 17) pxdata %&gt;% glimpse() ## Rows: 3,157,484 ## Columns: 11 ## $ p_title &lt;chr&gt; &quot;비율갑 연습생이 있다?&quot;, &quot;디모데 떨어진거 너무 아깝다&quot;, &quot;픽 남는데 추천해 줘&quot;, &quot;투표할때&quot;, &quot;남자 새... ## $ p_comment_num &lt;chr&gt; &quot;1&quot;, &quot;2&quot;, &quot;23&quot;, &quot;1&quot;, &quot;&quot;, &quot;11&quot;, &quot;&quot;, &quot;&quot;, &quot;1&quot;, &quot;5&quot;, &quot;3&quot;, &quot;2&quot;, &quot;&quot;, ... ## $ p_time &lt;chr&gt; &quot;2019-06-01 23:59:50&quot;, &quot;2019-06-01 23:59:48&quot;, &quot;2019-06-01 23:59... ## $ p_count &lt;chr&gt; &quot;145&quot;, &quot;117&quot;, &quot;124&quot;, &quot;24&quot;, &quot;42&quot;, &quot;311&quot;, &quot;155&quot;, &quot;103&quot;, &quot;134&quot;, &quot;3... ## $ p_recommend &lt;chr&gt; &quot;3&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;3&quot;, &quot;7&quot;, &quot;24&quot;, &quot;3&quot;, &quot;1&quot;, &quot;26&quot;, &quot;0&quot;, &quot;2&quot;, &quot;... ## $ p_ymd &lt;date&gt; 2019-06-01, 2019-06-01, 2019-06-01, 2019-06-01, 2019-06-01, 20... ## $ p_month &lt;fct&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ... ## $ p_day &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... ## $ p_hour &lt;fct&gt; 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,... ## $ p_wday &lt;ord&gt; 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, ... ## $ p_episode &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ... pxdata %&gt;% summary() ## p_title p_comment_num p_time p_count ## Length:3157484 Length:3157484 Length:3157484 Length:3157484 ## Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## p_recommend p_ymd p_month p_day p_hour ## Length:3157484 Min. :2019-06-01 6:1662384 19 : 218520 0 : 325406 ## Class :character 1st Qu.:2019-06-16 7:1495100 13 : 180866 1 : 276948 ## Mode :character Median :2019-06-29 15 : 163486 23 : 263078 ## Mean :2019-06-27 6 : 150334 22 : 164560 ## 3rd Qu.:2019-07-10 5 : 145498 2 : 163446 ## Max. :2019-07-19 1 : 142934 21 : 150364 ## (Other):2155846 (Other):1813682 ## p_wday p_episode ## 일:391790 Min. : 4.000 ## 월:378178 1st Qu.: 7.000 ## 화:344190 Median : 8.000 ## 수:313158 Mean : 8.201 ## 목:372724 3rd Qu.:10.000 ## 금:602086 Max. :11.000 ## 토:755358 is.na(pxdata) %&gt;% colSums() ## p_title p_comment_num p_time p_count p_recommend p_ymd ## 0 586318 0 0 0 0 ## p_month p_day p_hour p_wday p_episode ## 0 0 0 0 0 p_title p_comment_num p_time p_count p_recommend p_ymd p_month p_day p_hour p_wday p_episode 비율갑 연습생이 있다? 1 2019-06-01 23:59:50 145 3 2019-06-01 6 1 23 토 4 디모데 떨어진거 너무 아깝다 2 2019-06-01 23:59:48 117 0 2019-06-01 6 1 23 토 4 픽 남는데 추천해 줘 23 2019-06-01 23:59:43 124 0 2019-06-01 6 1 23 토 4 투표할때 1 2019-06-01 23:59:42 24 0 2019-06-01 6 1 23 토 4 남자 새끼들이 병신처럼 쳐울거나 2019-06-01 23:59:31 42 3 2019-06-01 6 1 23 토 4 근데 김요한은 운 하나는 존나 좋은거같아서 부럽긔 11 2019-06-01 23:59:25 311 7 2019-06-01 6 1 23 토 4 김성현 꼰대기 1도 없고 하찮다&lt;U+270B&gt; 2019-06-01 23:59:05 155 24 2019-06-01 6 1 23 토 4 캔디 롤 찍는 거냐?? 외로워도 슬퍼도 나는 안울어 2019-06-01 23:58:54 103 3 2019-06-01 6 1 23 토 4 남도현 움짤 프추좀 눌러주시긔 1 2019-06-01 23:58:52 134 1 2019-06-01 6 1 23 토 4 어제 상위권애들 왤케 거만했냐? 좆같게 5 2019-06-01 23:58:51 352 26 2019-06-01 6 1 23 토 4 따로 저장되어 있던 데이터들을 하나로 묶고, 분석에 필요한 새로운 변수열을 생성하였습니다. 마지막 에피소드는 2019-07-19에 방영 됐었습니다. 마지막 방송에서 진행된 시청자 문자투표는 방송이 시작한 시각인 밤 8시부터 밤 9시까지 진행이 됐었는데요. 투표가 종료된 이후의 데이터는 의미가 없으므로 데이터의 범위를 문자투표가 끝나는 시간인 2019-07-19 밤 9시까지로 설정하겠습니다. # 일간별 데이터 갯수 확인 table(pxdata$p_ymd) ## ## 2019-06-01 2019-06-02 2019-06-03 2019-06-04 2019-06-05 2019-06-06 2019-06-07 2019-06-08 ## 83378 42224 53010 36220 36050 36978 42978 62390 ## 2019-06-09 2019-06-10 2019-06-11 2019-06-12 2019-06-13 2019-06-14 2019-06-15 2019-06-16 ## 40998 40272 52476 41564 38440 60706 106806 56074 ## 2019-06-17 2019-06-18 2019-06-19 2019-06-20 2019-06-21 2019-06-22 2019-06-23 2019-06-24 ## 53456 41258 42184 40204 61090 134098 56028 46088 ## 2019-06-25 2019-06-26 2019-06-27 2019-06-28 2019-06-29 2019-06-30 2019-07-01 2019-07-02 ## 35840 38864 40950 62872 112904 65984 59556 48312 ## 2019-07-03 2019-07-04 2019-07-05 2019-07-06 2019-07-07 2019-07-08 2019-07-09 2019-07-10 ## 43126 64786 109448 113356 67502 69116 72502 58764 ## 2019-07-11 2019-07-12 2019-07-13 2019-07-14 2019-07-15 2019-07-16 2019-07-17 2019-07-18 ## 86502 88656 142426 62980 56680 57582 52606 64864 ## 2019-07-19 ## 176336 # 마지막날 문자투표 종료 이후 데이터 삭제 lastDay &lt;- pxdata %&gt;% filter(p_ymd == &#39;2019-07-19&#39;) %&gt;% filter(!p_hour %in% c(21, 22, 23, 24)) # 데이터 재 접합 pxdata &lt;- pxdata %&gt;% filter(p_ymd != &#39;2019-07-19&#39;) %&gt;% rbind(lastDay) # 데이터 확인 table(pxdata$p_ymd) ## ## 2019-06-01 2019-06-02 2019-06-03 2019-06-04 2019-06-05 2019-06-06 2019-06-07 2019-06-08 ## 83378 42224 53010 36220 36050 36978 42978 62390 ## 2019-06-09 2019-06-10 2019-06-11 2019-06-12 2019-06-13 2019-06-14 2019-06-15 2019-06-16 ## 40998 40272 52476 41564 38440 60706 106806 56074 ## 2019-06-17 2019-06-18 2019-06-19 2019-06-20 2019-06-21 2019-06-22 2019-06-23 2019-06-24 ## 53456 41258 42184 40204 61090 134098 56028 46088 ## 2019-06-25 2019-06-26 2019-06-27 2019-06-28 2019-06-29 2019-06-30 2019-07-01 2019-07-02 ## 35840 38864 40950 62872 112904 65984 59556 48312 ## 2019-07-03 2019-07-04 2019-07-05 2019-07-06 2019-07-07 2019-07-08 2019-07-09 2019-07-10 ## 43126 64786 109448 113356 67502 69116 72502 58764 ## 2019-07-11 2019-07-12 2019-07-13 2019-07-14 2019-07-15 2019-07-16 2019-07-17 2019-07-18 ## 86502 88656 142426 62980 56680 57582 52606 64864 ## 2019-07-19 ## 103092 마지막날의 데이터행이 124790개 에서 51546로 줄어든 것을 확인할 수 있습니다. 이것으로 전처리작업을 마치도록 하겠습니다. "],
["데이터-시각화.html", "Chapter 4 데이터 시각화 4.1 회차별 게시글 수 비교 4.2 요일별 게시글 수 비교 4.3 일자별 게시글 수 비교", " Chapter 4 데이터 시각화 본격적인 분석에 앞서 이전 파트에서 전처리한 데이터들을 기반으로 간단한 시각화를 진행해 볼까 합니다. 데이터 시각화를 통해 지금 가지고있는 데이터의 특성을 파악하고, 특징적인 정보가 있는지를 한번 살펴 보겠습니다. 먼저 앞장에서 다루었던 전처리한 데이터의 형태입니다. pxdata %&gt;% head(100) %&gt;% DT::datatable(options = list(scrollX = TRUE)) 4.1 회차별 게시글 수 비교 pxdata %&gt;% group_by(p_episode) %&gt;% count() ## # A tibble: 7 x 2 ## # Groups: p_episode [7] ## p_episode n ## &lt;fct&gt; &lt;int&gt; ## 1 5 165419 ## 2 6 168423 ## 3 7 200536 ## 4 8 207370 ## 5 9 252058 ## 6 10 278199 ## 7 11 270115 ## `summarise()` ungrouping output (override with `.groups` argument) 그래프의 x축은 방송 회차 기간을 의미하고, y축은 게시글 수를 의미합니다. 방송이 진행될수록 작성된 글 수는 증가하는 면모를 보입니다. 4.2 요일별 게시글 수 비교 pxdata %&gt;% group_by(p_wday) %&gt;% count() ## # A tibble: 7 x 2 ## # Groups: p_wday [7] ## p_wday n ## &lt;ord&gt; &lt;int&gt; ## 1 일 195895 ## 2 월 189089 ## 3 화 172095 ## 4 수 156579 ## 5 목 186362 ## 6 금 264421 ## 7 토 377679 ## `summarise()` ungrouping output (override with `.groups` argument) 방송이 방영되던 금요일과, 방송이 끝난 당일인 토요일에 작성된 글 수가 많은 것을 확인할 수 있습니다. 4.3 일자별 게시글 수 비교 pxdata %&gt;% group_by(p_ymd) %&gt;% count() %&gt;% mutate(p_wday = lubridate::wday(p_ymd, label = T), p_md = str_sub(p_ymd, 6, 10)) %&gt;% ggplot(aes(x = as.factor(p_md), y = n)) + geom_col(aes(fill = p_wday)) + theme(axis.text.x = element_text(angle = 90, size = 7)) + labs(x = &#39;날짜&#39;, y = &#39;게시글&#39;, fill = &quot;&quot;) pxdata %&gt;% group_by(p_ymd) %&gt;% count() %&gt;% mutate(p_wday = lubridate::wday(p_ymd, label = T), p_md = str_sub(p_ymd, 6, 10)) %&gt;% ggplot(aes(x = reorder(as.factor(p_md), -n), y = n)) + geom_col(aes(fill = p_wday)) + theme(axis.text.x = element_text(angle = 90, size = 7)) + labs(x = &#39;날짜&#39;, y = &#39;게시글&#39;, fill = &quot;&quot;) pxdata %&gt;% group_by(p_ymd) %&gt;% count() %&gt;% mutate(p_wday = lubridate::wday(p_ymd, label = T), p_md = str_sub(p_ymd, 6, 10)) %&gt;% ggplot(aes(x = as.factor(p_md), y = n)) + geom_col() + geom_text(aes(label = n), vjust = -1, size = 2) + theme(axis.text.x = element_text(size = 0)) + facet_wrap(~ p_wday) + labs(x = &#39;날짜&#39;, y = &#39;게시글&#39;) 일자별로 나누어 보았을 경우에도 금요일과 토요일에 사람들의 프로그램에 대한 관심도가 높은것을 확인할 수 있습니다. 다음으로 시청자들로부터 어느 연습생의 언급량이 많았는지를 도출해 보도록 하겠습니다. "],
["언급량-도출.html", "Chapter 5 언급량 도출 5.1 데이터 시각화 5.2 분석 범위 설정 5.3 언급량 집계 5.4 언급량 시각화", " Chapter 5 언급량 도출 사진출처 : 엠넷 이제 분석의 마무리 작업으로 지금까지 전처리한 데이터를 기반으로 어느 연습생의 언급량이 높았었는지를 직접 확인해 볼 시간입니다. 데이터 수집부터 이전에 진행한 시각화까지 다소 짧은 분량은 아니었는데요. 이번 시각화를 통해서 분석을 마무리를 지어볼까 합니다. 5.1 데이터 시각화 지금까지 수집한 데이터는 실제로 방송을 시청하는 시청자들이 게시판에 작성한 게시물들의 제목들(p_title) 입니다. 즉, 방송을 보고 투표를 할 확률이 높은 시청자들의 의견이 담긴 텍스트인데요. 분석에 앞서 한가지 가정을 했었습니다. 언급량이 높으면 높을수록 그만큼 인기도 많을 것이다 였는데요. 사람들 입에서 회자가 많이 된다는 것은 그만큼 관심과 인기가 있다는 의미이고, 그것이 투표량과도 상관이 있을것이다 가정하였습니다. 5.2 분석 범위 설정 “프로듀스 X 101”은 101명의 연습생들이 무대에서 경연을 통해 경쟁을 펼치고, 이를 본 시청자들의 투표를 통해서 최종 11명의 아이돌 멤버를 선발한다는 컨셉의 방송인데요. 마지막 방송날에 인기가 높았던 20명의 연습생들이 생방송 무대에서 경합을 펼쳤습니다. 마지막 방송까지 살아남은 최종 20명을 대상으로 분석을 진행해 보도록 하겠습니다. 미리 마지막 생방송에 진출한 스무명의 연습생 이름을 final_boylist.txt 파일에 저장해 두었었고, 이를 불러오겠습니다. boylist &lt;- readLines(&#39;./final_boylist.txt&#39;) boylist ## [1] &quot;김요한&quot; &quot;김우석&quot; &quot;이진혁&quot; &quot;한승우&quot; &quot;김민규&quot; &quot;조승연&quot; &quot;남도현&quot; &quot;송형준&quot; &quot;이은상&quot; ## [10] &quot;금동현&quot; &quot;차준호&quot; &quot;손동표&quot; &quot;황윤성&quot; &quot;강민희&quot; &quot;구정모&quot; &quot;이한결&quot; &quot;송유빈&quot; &quot;함원진&quot; ## [19] &quot;토니&quot; &quot;이세진&quot; 언급량은 연습생별로 연습생이 언급된 게시물들의 갯수가 몇개인지를 세어보는 방식으로 집계할 것입니다. 그런데 게시물들의 특성상 연습생의 fullname을 적는 경우보다 name만 적는 경우가 많이 있었기에 먼저 호출한 boylist에서 이름만 추출하겠습니다. boylist2 &lt;- str_sub(boylist, -2, -1) # 뒤에서 두번째 글자부터 뒤에서 첫번째 글자까지만을 저장 boylist2 ## [1] &quot;요한&quot; &quot;우석&quot; &quot;진혁&quot; &quot;승우&quot; &quot;민규&quot; &quot;승연&quot; &quot;도현&quot; &quot;형준&quot; &quot;은상&quot; &quot;동현&quot; &quot;준호&quot; &quot;동표&quot; ## [13] &quot;윤성&quot; &quot;민희&quot; &quot;정모&quot; &quot;한결&quot; &quot;유빈&quot; &quot;원진&quot; &quot;토니&quot; &quot;세진&quot; 5.3 언급량 집계 5.3.1 별명 정리 글을 작성할 때 이름을 적는 경우도 있지만 경우에 따라서는 별명이나 애칭으로 부르는 경우도 더러 있었습니다. 별명이나 애칭은 대상을 지칭하는 의미에서 결국 이름으로 부르는것과 다를바가 없을 것입니다. 때문에 각 연습생별로 자주 쓰이는 별명을 사전에 조사하여 데이터에서 그 별명을 연습생의 이름으로 변경시켜주는 작업을 진행하겠습니다. # 연습생별 별명 boy_nickname &lt;- list( c(&#39;욯&#39;), # 김요한 c(&#39;짤랑이&#39;), # 김우석 c(&#39;지녁&#39;), # 이진혁 c(&#39;스누피&#39;, &#39;식빵맨&#39;), # 한승우 c(&#39;밍규&#39;, &#39;밍구&#39;), # 김민규 c(&#39;조골무&#39;), # 조승연 c(&#39;도깅&#39;, &#39;도옵&#39;), # 남도현 c(&#39;형깅&#39;), # 송형준 c(), # 이은상 c(&#39;금동&#39;), # 금동현 c(), # 차준호 c(&#39;표동&#39;), # 손동표 c(&#39;쁘띠&#39;), # 황윤성 c(&#39;말티쥬&#39;, &#39;강미니&#39;), # 강민희 c(), # 구정모 c(), # 이한결 c(&#39;유넨&#39;), # 송유빈 c(&#39;함옵&#39;, &#39;함깅&#39;), # 함원진 c(&#39;토카츄&#39;), # 토니 c(&#39;마리몽&#39;) # 이세진 ) names(boy_nickname) &lt;- boylist # 별명 수정 전 pxdata %&gt;% filter(str_detect(p_title, &#39;욯&#39;)) %&gt;% nrow(); ## [1] 0 pxdata %&gt;% filter(str_detect(p_title, &#39;요한&#39;)) %&gt;% nrow() ## [1] 38578 # 별명 수정 for(i in seq(1, length(boylist))){ if(length(unlist(boy_nickname[boylist[i]])) != 0){ pxdata &lt;- pxdata %&gt;% mutate(p_title = stringi::stri_replace_all_fixed(p_title, paste(unlist(boy_nickname[i])), names(boy_nickname[i]), vectorize_all = F)) } } 검색을 통하여 별명을 찾아보았고, 연습생별 자주 쓰이는 별명을 list형식으로 저장하였습니다. 뚜렷한 별명이 없는 연습생은 공란으로 두었고, 별명의 경우이더라도 일상에서 많이 쓰이는 일반명사로 사용된 별명은 별명에서 제외하였습니다. # 별명 수정 후 pxdata %&gt;% filter(str_detect(p_title, &#39;욯&#39;)) %&gt;% nrow(); ## [1] 0 pxdata %&gt;% filter(str_detect(p_title, &#39;요한&#39;)) %&gt;% nrow() ## [1] 38578 별명이 모두 이름으로 변경된 것을 확인할 수 있습니다. 그런다음 for문을 통해 연습생별로 언급량을 집계해 보겠습니다. final_boys &lt;- c() boys &lt;- c() # 연습생별 언급게시글의 개수 `final_boys` 리스트에 저장 for(i in 1:length(boylist2)){ final_boys[i] &lt;- nrow(pxdata[grep(boylist2[i], pxdata$p_title), ]) } # 연습생 - 연습생 언급게시 개수 데이터프레임화 boys &lt;- data.frame(boy = boylist, mention = as.numeric(final_boys), stringsAsFactors = F) str(boys) ## &#39;data.frame&#39;:\t20 obs. of 2 variables: ## $ boy : chr &quot;김요한&quot; &quot;김우석&quot; &quot;이진혁&quot; &quot;한승우&quot; ... ## $ mention: num 38578 71188 26603 28371 46739 ... 이를 시각화하여 알아보도록 하겠습니다. 5.4 언급량 시각화 5.4.1 Barchart boys %&gt;% ggplot(aes(x = boy, y = mention)) + geom_col() + geom_text(aes(label = mention), vjust = -.5, size = 2) + theme(axis.text.x = element_text(angle = 45)) boys %&gt;% ggplot(aes(x = reorder(boy, -mention), y = mention)) + geom_col() + geom_text(aes(label = mention), vjust = -.5, size = 2) + theme(axis.text.x = element_text(angle = 45)) 시각화를 진행한 결과 김우석, 조승연, 김민규, 이은상, 구정모, 김요한, 남도현, 송형준, 한승우, 강민희, 이진혁 순으로 언급량이 많은것을 확인 할 수 있었습니다. 하지만 이것은 전체기간을(06/01 ~ 07/19) 대상으로 집계한 언급량이기 때문에 연습생들의 시간에 따른 언급량의 변화는 찾아 볼 수가 없네요. 방송이 진행되면서 멋진 무대를 소화해 낸 연습생은 순위가 올라간 경우도 있었고, 반대로 다른 여러 요인들로 인해 인기가 하락한 경우도 종종 볼 수 있었습니다. 그렇다면 이번에는 에피소드별로 연습생들의 언급량이 어떻게 변화했는지를 확인해 보도록 하겠습니다. 5.4.2 에피소드별 언급량 변화 # 에피소드별 언급량 temp_mention &lt;- c() episode_mention &lt;- c() for(i in seq(1, 20)){ print(boylist[i]) temp_mention &lt;- pxdata %&gt;% filter(str_detect(p_title, boylist2[i])) %&gt;% group_by(p_episode) %&gt;% summarise(mention = n()) %&gt;% mutate(boy = boylist[i]) episode_mention &lt;- rbind(episode_mention, temp_mention) } ## [1] &quot;김요한&quot; ## [1] &quot;김우석&quot; ## [1] &quot;이진혁&quot; ## [1] &quot;한승우&quot; ## [1] &quot;김민규&quot; ## [1] &quot;조승연&quot; ## [1] &quot;남도현&quot; ## [1] &quot;송형준&quot; ## [1] &quot;이은상&quot; ## [1] &quot;금동현&quot; ## [1] &quot;차준호&quot; ## [1] &quot;손동표&quot; ## [1] &quot;황윤성&quot; ## [1] &quot;강민희&quot; ## [1] &quot;구정모&quot; ## [1] &quot;이한결&quot; ## [1] &quot;송유빈&quot; ## [1] &quot;함원진&quot; ## [1] &quot;토니&quot; ## [1] &quot;이세진&quot; DT::datatable(episode_mention) 이렇게 에피소드별, 연습생별로 나누어진 데이터를 Barchart를 통해 시각화 해보겠습니다. episode_mention %&gt;% ggplot(aes(x = as.factor(p_episode), y = mention)) + geom_col() + geom_text(aes(label = mention), vjust = -1, size = 2) + facet_wrap( ~ boy) + labs(x = &#39;에피소드&#39;, y = &#39;언급량&#39;) 확실히 시간에 따른 연습생의 언급량이 어떻게 변화하였는지가 파악이 됩니다. 그렇지만 값이 높은 순서로 정렬이 되어 있지 않아 한눈에 파악하기 약간 어려운거 같은데 11주차 방송 기간을 기준으로 연습생의 언급량을 재정렬 해보겠습니다. 5.4.3 Barchart(11화 언급량 기준 정렬) episode_level &lt;- episode_mention %&gt;% filter(p_episode == 11) %&gt;% arrange(desc(mention)) %&gt;% .$boy episode_mention %&gt;% mutate(boy = factor(boy, levels = episode_level)) %&gt;% ggplot(aes(x = as.factor(p_episode), y = mention)) + geom_col() + geom_text(aes(label = mention), vjust = -1, size = 2) + facet_wrap( ~ boy) + labs(x = &#39;에피소드&#39;, y = &#39;언급량&#39;) 11회차를 기준으로는 조승연, 구정모, 김우석, 김민규, 한승우, 김요한, 남도현, 이은상, 이진혁, 금동현, 송형준 순으로 언급된 것을 볼 수 있습니다. 실제로 데뷔한 연습생들과 비교해 보니 전체 11명중 7명이 속하네요.(물론 잘못된 투표였다는 발표가 있었지만요.) 그렇지만 온라인 커뮤니티에서 시청자들이 어떤 연습생에 대해 많이 얘기하고 관심이 있어하는지를 엿볼 수 있던 기회였습니다. 이제 마지막으로 Bump chart를 제작하여 연습생들의 언급도가 어떻게 변화하였는지를 확인해 보도록 하겠습니다. 5.4.4 Bump chart Figure 5.1: Bump chart Bump chart는 순위가 있는 값들을 시각화하는데 사용이 되는 차트인데 위와 같이 순위의 변화를 관찰할때 유용하게 사용되는 차트입니다. library(plotly) # 테마 설정 my_theme &lt;- function() { # Colors color.background = &quot;white&quot; color.text = &quot;#22211d&quot; # Begin construction of chart theme_bw(base_size=15) + # Format background colors theme(panel.background = element_rect(fill=color.background, color=color.background)) + theme(plot.background = element_rect(fill=color.background, color=color.background)) + theme(panel.border = element_rect(color=color.background)) + theme(strip.background = element_rect(fill=color.background, color=color.background)) + # Format the grid theme(panel.grid.major.y = element_blank()) + theme(panel.grid.minor.y = element_blank()) + theme(axis.ticks = element_blank()) + # Format the legend # theme(legend.position = &quot;none&quot;) + # Format title and axis labels theme(plot.title = element_text(color=color.text, size=20, face = &quot;bold&quot;)) + theme(axis.title.x = element_text(size=14, color=&quot;black&quot;, face = &quot;bold&quot;)) + theme(axis.title.y = element_text(size=14, color=&quot;black&quot;, face = &quot;bold&quot;, vjust=1.25)) + theme(axis.text.x = element_text(size=10, vjust=0.5, hjust=0.5, color = color.text)) + theme(axis.text.y = element_text(size=10, color = color.text)) + theme(strip.text = element_text(face = &quot;bold&quot;)) + # Plot margins theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), &quot;cm&quot;)) } # 데이터 세팅 pxdata_bump &lt;- episode_mention %&gt;% group_by(p_episode) %&gt;% arrange(-mention) %&gt;% mutate(ranking = row_number()) # Bump Chart pxdata_plotly &lt;- pxdata_bump %&gt;% ggplot (aes(x = as.integer(p_episode), y = ranking, group = boy)) + geom_line (aes(color = boy, alpha = 1), size = 1.2) + geom_point(aes(color = boy, alpha = 1), size = 3) + geom_point(color =&#39;#FFFFFF&#39;, size = 1) + scale_x_continuous(breaks = 1:7, minor_breaks = 1:7, expand = c(.05, .05), labels = seq(5, 11)) + scale_y_reverse(breaks = 1:20) + geom_text(data = pxdata_bump %&gt;% filter(p_episode == 5), aes(label = boy, x = 0.6), hjust = 1, fontface = &#39;bold&#39;, color = &#39;#888888&#39;, size = 4) + geom_text(data = pxdata_bump %&gt;% filter(p_episode == 11), aes(label = boy, x = 7.4), hjust = 1, fontface = &#39;bold&#39;, color = &#39;#888888&#39;, size = 4) + labs(x = &#39;에피소드&#39;, y = &#39;순위&#39;, alpha = &quot;&quot;, color = &quot;&quot;) + my_theme() gp &lt;- ggplotly(pxdata_plotly) %&gt;% config(displayModeBar = F) %&gt;% layout(title = list(text = paste0(&#39;&lt;b&gt;&#39;, &#39;[PRODUCE X 101] WEEKLY BUMPCHART&#39;, &#39;&lt;br&gt;&#39;, &#39;&lt;sup&gt;&#39;, &#39;에피소드별 언급량 순위 변동&#39;, &#39;&lt;/sup&gt;&#39;, &#39;&lt;/b&gt;&#39;)), legend = list(y = 0), margin = list(t = 100)) gp 우측 이름을 더블클릭하면 개별 추세를 명확하게 확인할 수 있습니다. Bumpchart는 ggplot의 차트객체를 반응형 차트 형태로 변환시켜주는 plotly 패키지의 ggplotly() 함수를 사용하여 제작하였습니다. 마우스액션을 통해 좀더 세분화하여 차트를 탐색하여 볼 수 있습니다. 지금까지 데이터를 수집부터, 시각화 분석까지의 전반적인 과정들을 한번 훝어보았습니다. 예전에 취미삼아 혼자서만 분석하고 묵혀만 두었던 프로젝트였는데 블로그를 구축하고, 많은 분들께 공유할 수 있게 되어서 감회가 새롭네요. R 유저로서 blogdown 패키지로 블로그를 만들어 보고 싶었는데 올해가 넘어가기 전에 그 일을 끝마칠수 있어서 개인적으로 뿌듯합니다. 처음 작성한 글이라 미흡한 글이긴 하지만 도움이나 흥미가 있었기를 바라며 이만 마무리 짓도록 하겠습니다. 지금까지 긴글 읽어주셔서 감사합니다. "],
["모델링.html", "Chapter 6 모델링 6.1 파일 불러오기 &amp; 구조 확인 6.2 예측 방식 설정", " Chapter 6 모델링 방송이 끝난 2019년으로부터 지금은 1년이란 시간이 넘게 흘렀습니다. 그동안 “프로듀스 X 101” 조작 논란에 대한 재판이 진행이 되었었고, 재판 결과에 따른 새로운 사실도 드러났었습니다. 처음 이 글을 마친 2019년 연말에는 단순히 언급량을 집계하여 과거의 언급된 량을 순위처럼 취급하고 글을 끝 마쳤었는데, 1년이 지난 지금 새로운 방식으로 순위를 집계 해 보고자 합니다. 더불어 재판과 관련된 이슈또한 짚어보고 글을 마쳐보는것으로 하겠습니다. 6.1 파일 불러오기 &amp; 구조 확인 지난번에 전처리까지 끝마쳤던 데이터를 불러와 구조를 확인해 보도록 하겠습니다. library(dplyr) library(stringr) library(dlookr) pxdata &lt;- readRDS(str_glue(&#39;{dir}/pxdata.rds&#39;)) pxdata %&gt;% head() ## p_title p_comment_num p_time ## 1 비율갑 연습생이 있다? 1 2019-06-01 23:59:50 ## 2 디모데 떨어진거 너무 아깝다 2 2019-06-01 23:59:48 ## 3 픽 남는데 추천해 줘 23 2019-06-01 23:59:43 ## 4 투표할때 1 2019-06-01 23:59:42 ## 5 남자 새끼들이 병신처럼 쳐울거나 NA 2019-06-01 23:59:31 ## 6 근데 김요한은 운 하나는 존나 좋은거같아서 부럽긔 11 2019-06-01 23:59:25 ## p_count p_recommend p_ymd p_month p_day p_hour p_wday p_episode ## 1 145 3 2019-06-01 6 1 23 토 5 ## 2 117 0 2019-06-01 6 1 23 토 5 ## 3 124 0 2019-06-01 6 1 23 토 5 ## 4 24 0 2019-06-01 6 1 23 토 5 ## 5 42 3 2019-06-01 6 1 23 토 5 ## 6 311 7 2019-06-01 6 1 23 토 5 pxdata %&gt;% summary() ## p_title p_comment_num p_time p_count ## Length:1542120 Min. : 1.0 Length:1542120 Min. : 1.0 ## Class :character 1st Qu.: 1.0 Class :character 1st Qu.: 52.0 ## Mode :character Median : 3.0 Mode :character Median : 116.0 ## Mean : 4.6 Mean : 208.8 ## 3rd Qu.: 5.0 3rd Qu.: 223.0 ## Max. :8011.0 Max. :141344.0 ## NA&#39;s :586318 ## p_recommend p_ymd p_month p_day p_hour ## Min. : 0.000 Min. :2019-06-01 6:831192 13 : 90433 0 :162703 ## 1st Qu.: 0.000 1st Qu.:2019-06-15 7:710928 15 : 81743 1 :138474 ## Median : 1.000 Median :2019-06-29 6 : 75167 23 :115553 ## Mean : 5.358 Mean :2019-06-27 5 : 72749 2 : 81723 ## 3rd Qu.: 4.000 3rd Qu.:2019-07-10 19 : 72638 20 : 71493 ## Max. :3627.000 Max. :2019-07-19 1 : 71467 22 : 71385 ## (Other):1077923 (Other):900789 ## p_wday p_episode ## 일:195895 5 :165419 ## 월:189089 6 :168423 ## 화:172095 7 :200536 ## 수:156579 8 :207370 ## 목:186362 9 :252058 ## 금:264421 10:278199 ## 토:377679 11:270115 pxdata %&gt;% glimpse() ## Rows: 1,542,120 ## Columns: 11 ## $ p_title &lt;chr&gt; &quot;비율갑 연습생이 있다?&quot;, &quot;디모데 떨어진거 너무 아깝다&quot;, &quot;픽 남는데 추천해 줘&quot;, &quot;투표할때&quot;, &quot;남자 새... ## $ p_comment_num &lt;dbl&gt; 1, 2, 23, 1, NA, 11, NA, NA, 1, 5, 3, 2, NA, 7, 12, 1, 1, 2, 3,... ## $ p_time &lt;chr&gt; &quot;2019-06-01 23:59:50&quot;, &quot;2019-06-01 23:59:48&quot;, &quot;2019-06-01 23:59... ## $ p_count &lt;dbl&gt; 145, 117, 124, 24, 42, 311, 155, 103, 134, 352, 130, 172, 35, 2... ## $ p_recommend &lt;dbl&gt; 3, 0, 0, 0, 3, 7, 24, 3, 1, 26, 0, 2, 0, 6, 13, 1, 0, 11, 1, 3,... ## $ p_ymd &lt;date&gt; 2019-06-01, 2019-06-01, 2019-06-01, 2019-06-01, 2019-06-01, 20... ## $ p_month &lt;fct&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ... ## $ p_day &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... ## $ p_hour &lt;fct&gt; 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,... ## $ p_wday &lt;ord&gt; 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, 토, ... ## $ p_episode &lt;fct&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ... pxdata %&gt;% dlookr::diagnose() ## # A tibble: 11 x 6 ## variables types missing_count missing_percent unique_count unique_rate ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 p_title character 0 0 1473411 0.955 ## 2 p_comment_num numeric 586318 38.0 399 0.000259 ## 3 p_time character 0 0 1141175 0.740 ## 4 p_count numeric 0 0 8659 0.00561 ## 5 p_recommend numeric 0 0 1137 0.000737 ## 6 p_ymd Date 0 0 49 0.0000318 ## 7 p_month factor 0 0 2 0.00000130 ## 8 p_day factor 0 0 30 0.0000195 ## 9 p_hour factor 0 0 24 0.0000156 ## 10 p_wday ordered 0 0 7 0.00000454 ## 11 p_episode factor 0 0 7 0.00000454 분석에 대상이 되는 데이터는 총 11개의 변수와 1542120행으로 이루어진 것을 확인 할 수 있습니다. 데이터 수집 당시 획득한 변수로는 게시물의 제목을 의미하는 p_title과 게시물에 있는 댓글의 갯수를 의미하는 p_comment_num, 게시물의 작성시간인 p_time, 게시물의 조회수를 의미하는 p_count, 그리고 게시물 추천수의 갯수인 p_recommend 변수가 있는데요. 오늘은 이들 변수를 활용하여 예측 모델링을 수행해보는 과정을 알아보겠습니다. 6.2 예측 방식 설정 이전에 했던 작업들을 되짚어보면 단순히 연습생의 언급량 즉, 온라인 게시판에서 게시물 제목에 등장하는 연습생의 이름을 세어보는 형식으로 순위를 매겨 보았었습니다. 시청자들의 인기투표로 선발되는 프로그램이니 만큼 시청자들의 입으로부터 많이 회자가 되면 그만큼 인기가 있을 것이란 가정하에 진행한 방식이였는데요. 오늘은 이를 확장하여 분석 모델링을 수행하겠습니다. 먼저 모델링을 통해 알고자 하는 바가 무엇인지를 정하는 것이 우선이겠습니다. 각 연습생의 인기가 게시물에서의 등장 횟수로 반영된다고 가정하였으므로 종속변수로 언급량(mention)을 설정하겠습니다. 일간을 기준으로 그룹핑하여 각 연습생별 언급량 및 댓글수, 조회수, 추천수를 total이란 변수에 저장하겠습니다. temp &lt;- c() total &lt;- c() for(i in seq(1, length(boylist2))){ # print(i) temp &lt;- pxdata %&gt;% filter(str_detect(p_title, boylist2[i])) %&gt;% group_by(p_ymd) %&gt;% summarise(sum_mention = n(), sum_comment = sum(p_comment_num, na.rm = T), sum_count = sum(p_count), sum_recommend = sum(p_recommend)) %&gt;% mutate(boy = boylist[i]) total &lt;- rbind(total, temp) } total %&gt;% glimpse() ## Rows: 980 ## Columns: 6 ## $ p_ymd &lt;date&gt; 2019-06-01, 2019-06-02, 2019-06-03, 2019-06-04, 2019-06-05, 20... ## $ sum_mention &lt;int&gt; 1328, 450, 653, 557, 404, 291, 590, 1169, 740, 575, 479, 385, 1... ## $ sum_comment &lt;dbl&gt; 3150, 2241, 2900, 2342, 1991, 1155, 2218, 4499, 2955, 1469, 170... ## $ sum_count &lt;dbl&gt; 255460, 133261, 179084, 169972, 128181, 108997, 152461, 326816,... ## $ sum_recommend &lt;dbl&gt; 6739, 3335, 5763, 4725, 3350, 2757, 3960, 10802, 6112, 2314, 32... ## $ boy &lt;chr&gt; &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, &quot;김요한&quot;, ... DT::datatable(total) "],
["다중회귀분석.html", "Chapter 7 다중회귀분석 7.1 데이터 분할 7.2 모델 검정 7.3 결과", " Chapter 7 다중회귀분석 7.1 데이터 분할 언급량(sum_mention)을 종속변수로 하는 다중회귀모델을 생성하고, 모델이 추정하는 예측치를 바탕으로 순위 매겨보겠습니다. 여기서는 전체 데이터 중 마지막 방송이 방영된 날의 데이터를 테스트 데이터로, 그 이전의 데이터를 모델의 학습데이터로 분할해 주겠습니다. library(dplyr) library(ggplot2) library(lubridate) library(stringr) # train &amp; test total_train &lt;- total %&gt;% filter(p_ymd != &#39;2019-07-19&#39;) # 마지막날 이전 데이터 total_test &lt;- total %&gt;% filter(p_ymd == &#39;2019-07-19&#39;) # 마지막날 데이터 그런 다음 댓글, 조회수, 추천수를 독립변수로 하여 언급량을 추정하는 다중회귀모델을 생성합니다. total_lm &lt;- lm(sum_mention ~ sum_count + sum_recommend + sum_comment + boy, data = total_train) 7.2 모델 검정 생성한 회귀모델이 적절한 모델인지를 검정하는 과정이 필요로 합니다. 회귀분석이 지닌 기본적인 가정인 정규성, 선형성, 독립성, 등분산성을 검정하는 과정을 거쳐 모델이 적절한지를 파악하는 과정을 수행해 보도록 합니다. 생성한 모델을 plot()함수를 사용하여 잔차시각화를 진행합니다. par(mfrow = c(2, 2)) total_lm %&gt;% plot() par(mfrow = c(1, 1)) 7.2.1 정규성 선형회귀에서는 오차항이 정규분포를 따라야합니다. 그러므로 오차에 속한 잔차 역시 정규분포를 따라야 하는 가정을 따라야 합니다. 만약 잔차들이 정규성을 따른다면 Q-Q Plot상의 점들이 45도 각도의 직선에 밀접합니다. library(car) total_lm %&gt;% qqPlot() ## [1] 77 111 육안으로 보아도 정규성에 위배되는 것을 확인할 수 있습니다. 한편 shapiro.test()함수를 사용하면 더 정확하게 정규성을 검정할 수 있습니다. 잔차를 대상으로 Shapiro test 를 진행, p값이 기각역보다 크다면 잔차가 정규성을 띈다고 해석합니다. shapiro.test(total_lm$residuals) ## ## Shapiro-Wilk normality test ## ## data: total_lm$residuals ## W = 0.81877, p-value &lt; 2.2e-16 7.2.2 선형성 독립변수는 종속변수와의 관계에서 선형성을 띄어야 하는 가정을 충족해야 합니다. 선형성은 회귀 모델에서 모델의 통계적 유의성 검정을 통해 추측할 수 있습니다. 만약 모델이 선형성을 충족한다면 모델에 대한 p값이 유의하게 나올 것입니다. total_lm %&gt;% summary() ## ## Call: ## lm(formula = sum_mention ~ sum_count + sum_recommend + sum_comment + ## boy, data = total_train) ## ## Residuals: ## Min 1Q Median 3Q Max ## -924.50 -103.65 -20.83 76.50 2806.30 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.064e+02 3.585e+01 2.968 0.003072 ** ## sum_count 5.060e-03 2.597e-04 19.483 &lt; 2e-16 *** ## sum_recommend -3.656e-02 4.889e-03 -7.477 1.74e-13 *** ## sum_comment -1.373e-02 1.217e-02 -1.128 0.259436 ## boy구정모 -1.040e+02 4.973e+01 -2.091 0.036813 * ## boy금동현 2.557e+01 4.893e+01 0.522 0.601449 ## boy김민규 1.882e-01 4.937e+01 0.004 0.996959 ## boy김요한 -2.484e+02 5.019e+01 -4.950 8.79e-07 *** ## boy김우석 -2.159e+02 5.564e+01 -3.880 0.000112 *** ## boy남도현 -4.851e+02 5.136e+01 -9.444 &lt; 2e-16 *** ## boy손동표 -9.429e+01 4.893e+01 -1.927 0.054261 . ## boy송유빈 7.180e-01 4.900e+01 0.015 0.988312 ## boy송형준 -1.344e+02 4.921e+01 -2.731 0.006426 ** ## boy이세진 -6.016e+01 4.932e+01 -1.220 0.222881 ## boy이은상 -1.124e+02 4.944e+01 -2.274 0.023186 * ## boy이진혁 -3.728e+02 5.100e+01 -7.311 5.68e-13 *** ## boy이한결 -2.169e+02 4.909e+01 -4.418 1.11e-05 *** ## boy조승연 -5.814e+02 6.327e+01 -9.189 &lt; 2e-16 *** ## boy차준호 -7.508e+01 4.896e+01 -1.534 0.125470 ## boy토니 -1.087e+02 4.900e+01 -2.218 0.026801 * ## boy한승우 -2.645e+02 4.980e+01 -5.311 1.36e-07 *** ## boy함원진 -1.252e+02 4.897e+01 -2.556 0.010745 * ## boy황윤성 -1.179e+02 4.890e+01 -2.412 0.016078 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 239.4 on 937 degrees of freedom ## Multiple R-squared: 0.8115,\tAdjusted R-squared: 0.8071 ## F-statistic: 183.4 on 22 and 937 DF, p-value: &lt; 2.2e-16 car패키지에 있는 crPlots() 함수를 통해 개별 독립변수에 대한 선형성을 확인할 수 있습니다. 만약 plot에서 비선형성이 관찰된다면 이는 해당 변수가 선형성을 충족하지 못한것으로 볼 수 있습니다. total_lm %&gt;% crPlots() 7.2.3 독립성 독립성 가정은 크게 세가지를 충족하여야 합니다. 첫째 모델의 예측값과 잔차간의 독립성. 둘째 독립변수와 잔차간의 독립성. 셋째 잔차의 자기상관성. 먼저 예측값과 잔차간의 독립성은 앞서 보았던 잔차그래프중 첫번째 그래프에서 확인할 수 있습니다. total_lm %&gt;% plot(which = 1) 생성된 그래프를 보면 이상치의 영향으로 인해 정확한 판단은 어렵지만 잔차가 무작위적으로 퍼져있는것이 아닌 특정 부분에 쏠려 있는것으로 보여 집니다. 만약 잔차에 패턴이 보인다면 이는 곧 모델이 패턴에 해당하는 규칙성을 누락했단 의미로 해석될 수 있으며 모델에 추가해야할 요소가 남아있음을 의미합니다. 독립변수와 잔차간의 독립성은 상관계수 및 분포도로 판단할 수 있습니다. 모델에서 사용된 독립변인과 잔차를 묶어 GGally::ggpairs() 함수를 통해 확인해 보도록 하겠습니다. total_train %&gt;% select(sum_count, sum_recommend, sum_comment) %&gt;% mutate(residual = total_lm$residuals) %&gt;% GGally::ggpairs() 생성된 그래프를 보면 가운데를 기준으로 좌하단에는 변수간 산점도, 우상단에는 상관계수가 작성되어 있는 것을 확인할 수 있습니다. 여기에서 잔차(residual)와 각 독립변수(sum_count, sum_comment, sum_recommend)들 간의 상관계수는 0에 상회하는 것으로 거의 독립적인 것을 확인 할 수 있습니다. 그러나 각 독립변수들 간에 상관성이 높게 띄는것으로 보아 다중공선성이 크게 의심스러운 상황입니다. 마지막으로 잔차의 자기상관성은 car 패키지에 있는 durbinWatsonTest() 함수를 통해 진행할 수 있습니다. 더빈왓슨 테스트의 검정통계량 D-W Statistic 값은 0 ~ 4의 값을 가지며 0으로 가까울 수록 (잔차의) 양의 상관관계를, 4에 가까울수록 음의 상관관계를 가집니다. 2는 독립적인 것을 의미합니다. 여기서의 p_value는 자기상관성에 대한 것인데 기각역보다 작다면 자기상관관계가 있다고 해석합니다. total_lm %&gt;% durbinWatsonTest() ## lag Autocorrelation D-W Statistic p-value ## 1 0.1532939 1.68914 0 ## Alternative hypothesis: rho != 0 더빈왓슨 테스트의 결과 잔차에는 어느정도 자기상관성이 존재하여 독립성을 충족하지 못한것으로 보입니다. 7.2.4 등분산성 잔차의 분산은 예측값과 관계없이 고루 퍼져있어야 합니다. 이는 표준화된 잔차그래프에서 확인할 수 있으며 0 수평선을 기준으로 랜덤한 형태로 분포가 되어 있는 모습이 이상적인 등분산성의 형태입니다. total_lm %&gt;% plot(which = 3) 생성된 그래프를 살펴보니 그래프의 특정 부위값에 몰려 있으며, 붉은색 추세선 역시 수평보다 위로 치우쳐져 있어 등분산성 가정에는 못미치는 것으로 판단됩니다. 등분산성 검정을 위한 통계적 검정법에는 ncvTest() 함수를 사용하는 방법이 있습니다. total_lm %&gt;% ncvTest() ## Non-constant Variance Score Test ## Variance formula: ~ fitted.values ## Chisquare = 2195.865, Df = 1, p = &lt; 2.22e-16 ncvTest()의 수행으로 나오는 p_value는 모델의 등분산성에 대한 검정 결과입니다. 여기서의 귀무가설은 모델이 등분산성을 따른다이며, 대립가설로는 등분산성을 따르지 않는것으로 보여짐 입니다. p값이 낮게 나온것으로 보아 등분산성의 검정역시 통과하지 못한것으로 보입니다. 7.2.5 다중공선성 여러 변수들의 조합을 통해 만드는 다중회귀모델은 각 독립변수들의 독립성을 요구합니다. 만약 독립변수간에 강한 상관성이 존재한다면 이는 모델의 설명력에 왜곡을 불러올 것입니다. 다중회귀모델에서 독립변수에 대한 회귀계수는 다른 변인들이 0이라는 가정 하에 종속변수와 해당 독립변수 간의 선형성을 계산하는데 만약 독립변수끼리의 상관성이 존재한다면 상관성이 존재하는 변수들이 종속변수를 설명하는데 사용되는 분산이 중복되는 부분이 생겨 이는 곧 모델의 예측 성능 하락을 야기하고, 회귀식을 해석하는데 있어서 오류를 범하게 만드는 요인이 될 것입니다. 다중공선성을 계산하는 방법으로는 car패키지의 vif()(분산팽창지수)함수를 사용하는 방법이 있습니다. 변수간의 상관성을 계산하는 vif()함수는 통계값이 일반적으로 4미만일시 문제없다고 판단하고, 10을 넘어가면 다중공선성 문제가 있다고 판단합니다. total_lm %&gt;% vif() ## GVIF Df GVIF^(1/(2*Df)) ## sum_count 25.82365 1 5.081698 ## sum_recommend 12.75725 1 3.571729 ## sum_comment 10.79254 1 3.285200 ## boy 3.61625 19 1.034406 다중공선성을 계산한 결과 연습생 변수만을 제외한 모든 변수에서 다중공선성이 존재하는것을 볼 수 있습니다. 7.3 결과 모델 검정 결과 다중회귀분석은 적절한 방법이 아닌것으로 판단할 수 있습니다. 선형회귀모델이 가진 가정을 검정한 결과 선형성의 조건을 제외한 나머지 정규성, 독립성, 등분상성의 조건을 충족하지 못하였으며 더 나아가 다중회귀모델에서 가지는 다중공선성의 문제역시 보유하고 있는 것을 볼 수 있었습니다. 어찌보면 당연한 것이 이번 모델링에서 사용한 변수들은 각각 게시물에 대한 조회수, 댓글수, 추천수인데 상식적으로 생각해봐도 조회수가 높은 게시물은 댓글과 추천을 많이 가질 확률이 높을 것입니다. 각 지표가 높게 나온 이유는 무엇보다 게시물의 내용이라는 공통된 요인이 유저들의 이목을 집중시켰을 테니까요. 그리고 무엇보다도 데이터가 가진 시계열적 요소를 배재한체 다중회귀분석을 진행한 것에 대한 문제점도 있었습니다. 시계열 데이터가 지닌 특징중에 하나인 자기상관성의 영향력도 무시하지 못할 요인인데 말이죠. library(forecast) ggAcf(total_lm$residuals) ggAcf()는 ACF(Auto Correlation Function)(자기상관함수)를 계산하여 시각화한 함수로 과거 특정 시점과의 자기상관성을 계산하여 그래프로 표현하는 함수입니다. 푸른색 점선을 넘어가는 직선은 해당시점(lag)과의 상관성이 존재한다는 의미인데(시점의 자기상관성이 통계적으로 유의하다) 여기서 회귀모델의 잔차는 다수의 시점에서 자기상관성이 관측되는 것을 볼 수 있습니다. 이럴경우 일반적인 회귀모델보다 시계열분석이 더 적합할 수 있습니다. "],
["시계열-분석1.html", "Chapter 8 시계열 분석1 8.1 ts객체 8.2 모델링 8.3 모델 평가 8.4 시계열 교차 검증", " Chapter 8 시계열 분석1 기후나 주가지수와 같이 시간에 따라 관찰된 값들을 분석하는 경우 시계열분석 기법을 사용합니다. 과거의 값들을 토대로 미래의 값을 추정하거나 패턴들의 특징을 파악하기 위해 분석하는 기법입니다. 이전에 일간별로 수집한 데이터들을 전처리하여 연습생별 언급량을 계산하는 과정을 진행하였었는데 오늘은 이 데이터를 활용, 각 연습생별 적절한 모델을 찾고 해당 모델을 토대로 예측값을 도출하여 이를 비교하는 과정을 진행하겠습니다. 8.1 ts객체 time-series의 약자인 ts객체는 이름에 나와있는 것처럼 시계열분석을 위해 사용되는 객체 중 하나입니다. 시간의 흐름에 따라 연속적인 속성을 지닌 변수에 ts()함수를 적용하여 생성할 수 있으며, 시계열에 존재하는 주기를 frequency 옵션을 사용하여 지정할 수 있는것이 특징입니다. 이전장에서 사용한 total변수를 사용하여 연습생들의 언급량의 총 합을 계산하여 이를 ts객체로 생성해 보겠습니다. library(dplyr) ts_mention &lt;- total %&gt;% group_by(p_ymd) %&gt;% summarise(sum_mention = sum_mention %&gt;% sum()) %&gt;% ts(frequency = 7) ts_mention ## Time Series: ## Start = c(1, 1) ## End = c(7, 7) ## Frequency = 7 ## p_ymd sum_mention ## 1.000000 18048 16441 ## 1.142857 18049 7624 ## 1.285714 18050 10450 ## 1.428571 18051 6213 ## 1.571429 18052 6596 ## 1.714286 18053 7046 ## 1.857143 18054 7027 ## 2.000000 18055 13243 ## 2.142857 18056 7902 ## 2.285714 18057 7904 ## 2.428571 18058 11147 ## 2.571429 18059 8051 ## 2.714286 18060 7396 ## 2.857143 18061 8489 ## 3.000000 18062 19602 ## 3.142857 18063 10050 ## 3.285714 18064 10682 ## 3.428571 18065 6534 ## 3.571429 18066 6582 ## 3.714286 18067 6531 ## 3.857143 18068 11108 ## 4.000000 18069 19281 ## 4.142857 18070 10440 ## 4.285714 18071 9554 ## 4.428571 18072 6465 ## 4.571429 18073 6286 ## 4.714286 18074 6051 ## 4.857143 18075 11791 ## 5.000000 18076 24992 ## 5.142857 18077 14246 ## 5.285714 18078 12820 ## 5.428571 18079 11127 ## 5.571429 18080 8714 ## 5.714286 18081 13161 ## 5.857143 18082 16611 ## 6.000000 18083 26408 ## 6.142857 18084 14017 ## 6.285714 18085 12060 ## 6.428571 18086 15208 ## 6.571429 18087 11365 ## 6.714286 18088 18463 ## 6.857143 18089 18618 ## 7.000000 18090 34965 ## 7.142857 18091 15609 ## 7.285714 18092 13102 ## 7.428571 18093 14000 ## 7.571429 18094 11601 ## 7.714286 18095 13098 ## 7.857143 18096 21905 8.2 모델링 8.2.1 시계열 회귀 모델 forecast패키지에 포함되어 있는 tslm() 함수는 시계열 회귀분석을 하는데 용이한 함수입니다. 일반적으로 lm()함수와 동일한 기능을 수행하지만 시계열 데이터가 보유하고 있는 계절성과 추세를 자동으로 계산하여 각각 season, trend 변수로 치환하고, 이를 회귀분석에 사용할 수 있도록 해줍니다. library(forecast) # tslm 모델 생성 mod_tslm &lt;- tslm(sum_mention ~ trend + season, data = ts_mention) # 모델 결과 mod_tslm %&gt;% summary() ## ## Call: ## tslm(formula = sum_mention ~ trend + season, data = ts_mention) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5591.7 -1803.1 -389.8 1262.4 7884.2 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 16949.91 1184.11 14.314 &lt; 2e-16 *** ## trend 235.60 27.49 8.572 1.10e-10 *** ## season2 -10956.17 1440.04 -7.608 2.31e-09 *** ## season3 -11665.49 1440.83 -8.096 4.89e-10 *** ## season4 -12740.80 1442.14 -8.835 4.89e-11 *** ## season5 -14619.12 1443.97 -10.124 1.02e-12 *** ## season6 -13061.72 1446.32 -9.031 2.68e-11 *** ## season7 -9896.89 1449.19 -6.829 2.87e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2694 on 41 degrees of freedom ## Multiple R-squared: 0.8255,\tAdjusted R-squared: 0.7957 ## F-statistic: 27.71 on 7 and 41 DF, p-value: 1.275e-13 생성된 모델의 결과를 살펴보면 자동으로 추세변수와 계절성 변수를 계산하여 이를통해 회귀식을 생성한 것을 볼 수 있습니다. 이렇게 생성된 모델을 forecast()함수를 통해 미래의 예측값을 도출해 낼 수 있습니다. # 예측값 도출 mod_tslm_pred &lt;- mod_tslm %&gt;% forecast(h = 7) mod_tslm_pred ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 8.000000 28729.98 24847.59 32612.37 22710.491 34749.47 ## 8.142857 18009.41 14127.02 21891.80 11989.920 24028.90 ## 8.285714 17535.69 13653.30 21418.08 11516.205 23555.18 ## 8.428571 16695.98 12813.59 20578.37 10676.491 22715.47 ## 8.571429 15053.27 11170.88 18935.65 9033.777 21072.75 ## 8.714286 16846.27 12963.88 20728.65 10826.777 22865.75 ## 8.857143 20246.69 16364.30 24129.08 14227.205 26266.18 모델을 통한 예측값의 점추정 값과 신뢰구간을 계산해 줌을 볼 수 있습니다. 이렇게 계산된 예측값을 시각화하여 볼 수 있습니다. # 예측값 시각화 mod_tslm_pred %&gt;% plot() 최종적으로 모델을 사용하기 이전에 모델의 성능을 측정하여 해당 모델이 다른 모델에 비해 성능적으로 우위가 있는지를 판단할 수 있습니다. 모델의 성능을 측정하는 방법에는 다양한 방법들이 존재합니다. 함수 accuracy()를 사용하면 주요 성능을 계산하여 보여줌으로서 모델의 성능을 파악하는데 용이합니다. # 모델 정확성 mod_tslm_pred %&gt;% accuracy() ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set -1.949778e-13 2463.901 1914.331 -2.689877 17.70896 0.7446207 0.3114162 8.2.2 ETS 지수평활법(Exponential Smoothing)은 과거 시점의 값들을 지수적으로 감쇠시키는 가중치를 부여, 그 과정에서 시계열 데이터가 지니고 있는 추세적 특징과 계절성을 함께 사용하여 미래값을 추정하는 방식입니다. ets()함수를 통해 사용할 수 있습니다. # ETS 모델 생성 mod_ets &lt;- ets(ts_mention[, &#39;sum_mention&#39;]) mod_ets ## ETS(M,N,M) ## ## Call: ## ets(y = ts_mention[, &quot;sum_mention&quot;]) ## ## Smoothing parameters: ## alpha = 0.4791 ## gamma = 3e-04 ## ## Initial states: ## l = 10157.3035 ## s = 1.0528 0.785 0.66 0.8397 0.895 0.9398 ## 1.8278 ## ## sigma: 0.2171 ## ## AIC AICc BIC ## 963.9526 969.7421 982.8708 # ETS 모델 예측값 mod_ets_pred &lt;- mod_ets %&gt;% forecast(h = 7) # ETS 모델 예측값 시각화 mod_ets_pred %&gt;% plot() # ETS 모델 성능 mod_ets_pred %&gt;% accuracy() ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 366.2466 2238.365 1732.237 -0.02427324 14.99357 0.673791 0.1015756 8.2.3 ARIMA 시계열 데이터의 자기회귀성을 통해 미래값을 추정하는 arima 모델을 사용하여 미래값을 추정할 수 있습니다. arima 모델은 평균과 분산이 일정한 정상성의 성격을 가진 시계열 데이터를 자기회귀모델(Auto-Regressive model)과 이동평균모델(Moving Average model)을 결합한 모델로서 각각 특정 과거시점까지의 계수의 자기상관성과 오차의 자기상관성을 하나의 모델로서 구현한 것입니다. 본래 arima 모델을 구하기 위해서는 먼저 차분을 통한 시계열의 정상성 확보 이후 ACF와 PACF를 통한 적절한 AR 차수와 MA 차수를 구하는 과정이 필요하지만 R에서 제공하는 auto.arima()함수는 (AICc값의 최소로 하는 모델을 찾아) 최적의 arima 모델을 찾아 반환하여 줍니다. # arima 모델 생성 mod_arima &lt;- auto.arima(ts_mention[, &#39;sum_mention&#39;], stepwise = FALSE) mod_arima ## Series: ts_mention[, &quot;sum_mention&quot;] ## ARIMA(0,0,2)(1,1,0)[7] with drift ## ## Coefficients: ## ma1 ma2 sar1 drift ## 0.3016 0.4263 -0.4444 224.0282 ## s.e. 0.1509 0.1442 0.1681 68.6841 ## ## sigma^2 estimated as 6908166: log likelihood=-389.24 ## AIC=788.49 AICc=790.15 BIC=797.18 # arima 모델 예측값 mod_arima_pred &lt;- mod_arima %&gt;% forecast(h = 7) # arima 모델 예측값 시각화 mod_arima_pred %&gt;% plot() # arima 모델 성능 mod_arima_pred %&gt;% accuracy() ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set -28.30705 2314.596 1719.968 -4.203 14.63408 0.669019 -0.0157034 8.3 모델 평가 accuracy()함수를 통해 계산한 모델들의 성능을 대조해 봄으로서 각 모델들의 성능을 한눈에 파악하고, 최적의 퍼포먼스를 보여주는 모델을 파악하여 최종 사용 모델로 선정할 수 있습니다. 생성한 모델들의 성능을 하나의 데이터 프레임으로 묶어 지표 기준으로 재정렬하는 과정을 진행합니다. # 모델별 정확도 변수 생성 mod_tslm_accuracy &lt;- mod_tslm %&gt;% accuracy() mod_ets_accuracy &lt;- mod_ets %&gt;% accuracy() mod_arima_accuracy &lt;- mod_arima %&gt;% accuracy() # 모델 정확도 이름 지정 dimnames(mod_tslm_accuracy)[[1]] &lt;- &#39;mod_tslm&#39; dimnames(mod_ets_accuracy)[[1]] &lt;- &#39;mod_ets&#39; dimnames(mod_arima_accuracy)[[1]] &lt;- &#39;mod_arima&#39; # RMSE 기준 정렬 rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %&gt;% as.data.frame() %&gt;% arrange(RMSE) ## ME RMSE MAE MPE MAPE MASE ACF1 ## mod_ets 3.662466e+02 2238.365 1732.237 -0.02427324 14.99357 0.6737910 0.1015756 ## mod_arima -2.830705e+01 2314.596 1719.968 -4.20300032 14.63408 0.6690190 -0.0157034 ## mod_tslm -1.949778e-13 2463.901 1914.331 -2.68987699 17.70896 0.7446207 0.3114162 # MAPE 기준 정렬 rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %&gt;% as.data.frame() %&gt;% arrange(MAPE) ## ME RMSE MAE MPE MAPE MASE ACF1 ## mod_arima -2.830705e+01 2314.596 1719.968 -4.20300032 14.63408 0.6690190 -0.0157034 ## mod_ets 3.662466e+02 2238.365 1732.237 -0.02427324 14.99357 0.6737910 0.1015756 ## mod_tslm -1.949778e-13 2463.901 1914.331 -2.68987699 17.70896 0.7446207 0.3114162 # ACF1(1시차 자기상관성) 기준 정렬 rbind(mod_tslm_accuracy, mod_ets_accuracy, mod_arima_accuracy) %&gt;% as.data.frame() %&gt;% arrange(ACF1) ## ME RMSE MAE MPE MAPE MASE ACF1 ## mod_arima -2.830705e+01 2314.596 1719.968 -4.20300032 14.63408 0.6690190 -0.0157034 ## mod_ets 3.662466e+02 2238.365 1732.237 -0.02427324 14.99357 0.6737910 0.1015756 ## mod_tslm -1.949778e-13 2463.901 1914.331 -2.68987699 17.70896 0.7446207 0.3114162 거의 모든 지표에서 arima 모델이 우위에 있는것으로 나오나 RMSE에서만은 ets 모델이 근소하게 우위에 있는것을 확인할 수 있습니다. 8.4 시계열 교차 검증 단일 데이터에 대한 모델링은 모델이 데이터의 특성을 지나치게 학습하여 일반화된 예측에서 성능이 되려 떨어지게 되는 과적합의 위험성이 있습니다. 모델의 과적합을 방지하기 위해 데이터의 부분추출을 통한 학습을 여러번 수행하고, 각 학습마다의 성능을 측정하여 그 성능값을 평균내는 방식의 교차검증을 통해 과적합의 위험성을 방지할 수 있습니다. 시계열 데이터에서의 교차검정은 tsCV()함수를 통해 수행할 수 있습니다. tsCV()함수는 특정 과거시점 까지의 데이터를 학습하고 누적 순차적으로 최신 데이터까지의 학습을 수행하는데 output으로 모델의 잔차를 반환하여 줍니다. 해당 잔차를 통해 각 모델별 성능을 계산하여 비교를 진행, 최적의 모델을 선택하여 사용할 수 있습니다. 8.4.1 교차검증 함수 생성 tsCV()의 인수로 시계열 모델링을 수행할 함수를 지정하는 과정이 필요합니다. 시계열 교차검증에 적합한 모델 함수를 생성하도록 하겠습니다. # 시계열 교차검증용 모델 생성 forecast_arima &lt;- function(x, h){ auto.arima(x, stepwise = FALSE) %&gt;% forecast(h = h) } forecast_tslm &lt;- function(x, h){ tslm(x ~ trend + season, data = x) %&gt;% forecast(h = h) } forecast_ets &lt;- function(x, h){ ets(x) %&gt;% forecast(h = h) } # 교차검증 잔차 tslm_cv_residual &lt;- tsCV(ts_mention[, &#39;sum_mention&#39;], forecast_tslm, h = 1) ets_cv_residual &lt;- tsCV(ts_mention[, &#39;sum_mention&#39;], forecast_ets, h = 1) arima_cv_residual &lt;- tsCV(ts_mention[, &#39;sum_mention&#39;], forecast_arima, h = 1) # 모델 평가 매트릭 함수 생성(RMSE) RMSE &lt;- function(res){ mean(res^2, na.rm = TRUE)^0.5 } data.frame( tslm = tslm_cv_residual %&gt;% RMSE(), ets = ets_cv_residual %&gt;% RMSE(), arima = arima_cv_residual %&gt;% RMSE() ) ## tslm ets arima ## 1 3453.27 3621.207 3845.548 모델별 교차검증 결과로 나온 잔차에 RMSE를 기준으로 계산한 결과 시계열 회귀 모델(tslm)의 성능이 상대적으로 우수한 것으로 판별이 되었습니다. 8.4.2 최종 모델링 교차검증 모델 평가를 통해 시계열 회귀 모델을 사용하는 것이 괜찮다고 나왔으므로 이전에 생성한 시계열 회귀 모델을 최종 모델로 선정하겠습니다. mod_tslm &lt;- tslm(sum_mention ~ trend + season, data = ts_mention) 8.4.3 잔차 검정 마지막으로 시계열 모델의 잔차가 백색잡음을 띄는지를 검정하도록 하겠습니다. 만약 잔차에 패턴 혹은 상관성이 존재할 경우 모델이 이는 회귀모델의 독립성 가정에 위배되므로 잘못된 모델이라고 할 수 있습니다. mod_tslm %&gt;% checkresiduals() ## ## Breusch-Godfrey test for serial correlation of order up to 11 ## ## data: Residuals from Linear regression model ## LM test = 12.45, df = 11, p-value = 0.3308 생성된 그래프의 잔차분포는 조금은 치우쳐 있지만 정규분포의 형태와 흡사해 보이고 acf역시 크게 이상은 없어보입니다. checkresiduals()함수는 모델이 회귀분석 모델이면 Breusch-Godfrey test를, 그렇지 않으면 Ljung-Box test를 진행합니다. 두 검정법 모두 귀무가설로 잔차의 상관성이 통계적으로 유의성이 존재하지 않는다 정의하고 있습니다.(백색잡음이라 보여짐) checkresiduals()함수의 결과로 p_value &gt; 0.05 인 것을 보아 모델의 잔차에는 이상이 없어 보입니다. 8.4.4 예측 잔차검정까지 마친 모델을 대상으로 미래 시점의 값을 추정해 볼 수 있습니다. 앞서 사용한 forecast()함수를 통해 시계열 회귀 모델의 미래 추정값을 계산하고, 이에대한 신뢰구간을 계산하여 파악할 수 있습니다. mod_tslm %&gt;% forecast(h = 7) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 8.000000 28729.98 24847.59 32612.37 22710.491 34749.47 ## 8.142857 18009.41 14127.02 21891.80 11989.920 24028.90 ## 8.285714 17535.69 13653.30 21418.08 11516.205 23555.18 ## 8.428571 16695.98 12813.59 20578.37 10676.491 22715.47 ## 8.571429 15053.27 11170.88 18935.65 9033.777 21072.75 ## 8.714286 16846.27 12963.88 20728.65 10826.777 22865.75 ## 8.857143 20246.69 16364.30 24129.08 14227.205 26266.18 모델을 생성하는데 사용된 총 언급량 데이터와 이를 시계열 회귀모델에 적합한 값 그리고 회귀모델의 예측값까지 시각화하여 확인할 수 있습니다. ggplot2 문법을 따르는 autoplot()함수를 통해 시계열 시각화를 수월하게 할 수 있습니다. library(ggplot2) ts_mention[, &#39;sum_mention&#39;] %&gt;% autoplot(series = &#39;Original&#39;) + autolayer(fitted(mod_tslm), series = &#39;tslm_fitted&#39;) + autolayer(forecast(mod_tslm), h = 7, series = &#39;tslm_forecast&#39;) + scale_color_manual(values = c(&#39;Original&#39; = &#39;black&#39;, &#39;tslm_fitted&#39; = &#39;red&#39;, &#39;tslm_forecast&#39; = &#39;blue&#39;), breaks = c(&#39;Original&#39;, &#39;tslm_fitted&#39;, &#39;tslm_forecast&#39;)) ## Warning: Ignoring unknown parameters: h 위의 과정을 통해 검정선의 실제 데이터(총 언급량)과 붉은선의 모델에 적합한 값을 비교하여 볼 수 있고, 파란 음영처리된 신뢰구간을 포함한 미래 예측값을 하나의 그래프로 표현하여 한 눈에 볼 수 있습니다. "],
["시계열-분석2.html", "Chapter 9 시계열 분석2 9.1 연습생별 모델링 함수 생성 9.2 사용 모델 확인 9.3 모델 시각화 9.4 결론", " Chapter 9 시계열 분석2 지금까지 연습생들의 언급량을 총 합산한 데이터를 토대로 시계열 예측 과정을 진행하였습니다. 이 과정을 개별 연습생에 대한 언급량 데이터에 적용하여 각각의 연습생들에 적법한 모델을 찾고 그 모델을 토대로 바로 다음 시점의 언급량을 추정, 이를 대조하여 언습생들의 인기를 추측해 보겠습니다. 9.1 연습생별 모델링 함수 생성 # 연습생별 최적 성능 모델 생성 함수 boy_model &lt;- function(total, final_boy){ # 연습생 언급량 필터링 &amp; ts 객체 변환 boy_ts &lt;- total %&gt;% filter(boy == final_boy) %&gt;% ts(frequency = 7) # 시계열 교차검증용 모델 지정 forecast_arima &lt;- function(x, h){ auto.arima(x, stepwise = FALSE) %&gt;% forecast(h = h) } forecast_tslm &lt;- function(x, h){ tslm(x ~ trend + season, data = x) %&gt;% forecast(h = h) } forecast_ets &lt;- function(x, h){ ets(x) %&gt;% forecast(h = h) } # 모델 평가 매트릭 함수 지정(RMSE) RMSE &lt;- function(y){ mean(y^2, na.rm=TRUE)^0.5 } # 시계열 교차검증 tslm_cv_residual &lt;- tsCV(boy_ts[, &#39;sum_mention&#39;], forecast_tslm, h = 1) ets_cv_residual &lt;- tsCV(boy_ts[, &#39;sum_mention&#39;], forecast_ets, h = 1) arima_cv_residual &lt;- tsCV(boy_ts[, &#39;sum_mention&#39;], forecast_arima, h = 1) # 최적 성능순 모델 이름 추출 models &lt;- data.frame(model = c(&#39;tslm&#39;, &#39;ets&#39;, &#39;arima&#39;), score = c(RMSE(tslm_cv_residual), RMSE(ets_cv_residual), RMSE(arima_cv_residual))) %&gt;% arrange(score) %&gt;% .$model # 모델 적용 함수 select_model &lt;- function(type){ if(type == &#39;tslm&#39;){ final_model &lt;- tslm(sum_mention ~ trend + season, data = boy_ts) } if(type == &#39;ets&#39;){ final_model &lt;- ets(boy_ts[, &#39;sum_mention&#39;]) } if(type == &#39;arima&#39;){ final_model &lt;- auto.arima(boy_ts[, &#39;sum_mention&#39;], stepwise = FALSE) } return(final_model) } # 최적 모델 적용 for(model in models){ # print(model) final_model &lt;- select_model(type = model) # 잔차검정 if(checkresiduals(final_model, plot = FALSE)$p.value &gt; 0.05){ # 테스트 통과시 for문 종료 break } } # 모든 모델이 잔차검정 통과 못할 시 # 차선책으로 가장 좋은 성능을 내는 첫번째 모델 선택 if(checkresiduals(final_model, plot = FALSE)$p.value &lt;= 0.05 &amp;&amp; model == models[3]){ model &lt;- models[1] final_model &lt;- select_model(type = model) } # 최적 모델, 사용된 모델명 반환 boy_model &lt;- list( model = final_model, use_model = model ) return(boy_model) } final &lt;- c() final_boy &lt;- c() for(final_boy in boylist){ print(final_boy) final[[final_boy]] &lt;- boy_model(total, final_boy) } 연습생 개개인의 상황에 맞는 우수한 성능 모델을 찾아 잔차검정까지 마친 최적의 모델을 찾아 반환하는 boy_model()함수를 사용하여 그 결과물을 final 객체에 저장하였습니다. 9.2 사용 모델 확인 연습생들에 적용된 최적의 모델이 무엇인지 확인하겠습니다. final %&gt;% purrr::map(function(x){x$use_model}) %&gt;% do.call(rbind, .) %&gt;% as.data.frame() %&gt;% kableExtra::kable() %&gt;% stringr::str_remove(&#39;V1&#39;) %&gt;% shiny::HTML() 김요한 tslm 김우석 tslm 이진혁 arima 한승우 arima 김민규 arima 조승연 tslm 남도현 tslm 송형준 arima 이은상 tslm 금동현 tslm 차준호 arima 손동표 tslm 황윤성 tslm 강민희 tslm 구정모 ets 이한결 arima 송유빈 tslm 함원진 arima 토니 arima 이세진 arima 연습생별 최적 모델을 찾는 함수에서 지정한 use_model변수는 개별 모델을 적용할 때 사용한 모델의 이름을 저장한 변수입니다. 이 변수만을 별도로 보니 연습생별로 모델을 적용하는데 있어서 대체로 arima 모델과 시계열 회귀모델이 선택되고 ets 모델은 상대적으로 덜 선택된 것을 볼 수 있습니다. 이처럼 언급량 데이터는 성격과 형태가 유사한 데이터 이지만 데이터가 지닌 시계열적 특징에 따라 적용된 모델이 상이한 것을 확인할 수 있었습니다. 9.3 모델 시각화 개개인의 데이터에 맞춘 모델을 이전장에서 했던 유사한 시각화 방식으로 파악할 수 있습니다. 생성된 모델과 실제 데이터를 모델에 적합한 값 그리고 모델이 예측한 값을 연습생별로 시각화하여 살펴보도록 하겠습니다. # 모델 시각화 함수 생성 library(tidyquant) boy_plot &lt;- function(boy){ forecast(final[[boy]]$model, h = 7) %&gt;% autoplot() + autolayer(fitted(final[[1]]$model), series = &#39;fitted&#39;, color = &#39;red&#39;) + scale_x_continuous(breaks = seq(1, 9), labels = str_glue(&quot;{(seq(1, 7) + 4) %&gt;% append(c(&#39;final&#39;, &#39;predict&#39;))}&quot;)) + theme_tq() + labs(subtitle = boy, x = &#39;episode&#39;, y = &#39;sum_mention&#39;) + theme(plot.subtitle = element_text(hjust = 1, size = 12)) } # 연습생별 모델 그래프 저장 i = 0 final_plot &lt;- c() for(i in seq(1, 20)){ final_plot[[i]] &lt;- boy_plot(boylist[i]) } library(gridExtra) do.call(&#39;grid.arrange&#39;, c(final_plot, ncol = 1)) 방송이 방영된 회차에 발생한 실제 언급량을 검정선에, 생성된 모델에 실제 언급량을 반영한 모델값을 붉은색선, 그리고 방송이 끝난 후의 언급량을 모델이 예측한 값을 푸른색 신뢰구간과 함께 파란색선으로 표현하였습니다. 연습생별로 모델이 추정한 미래 값이 서로 상이한 것을 볼 수 있습니다. 9.4 결론 지금까지 적지 않은 과정을 통해 시계열 분석 절차를 진행 해 왔습니다. 모델에 사용된 데이터는 커뮤니티 게시판에서 시청자들 혹은 방송에 관심이 있는 유저들이 작성한 게시글의 제목으로, 이 제목 중 특정 연습생 인물의 이름 또는 별명을 일간별로 계산하여 이를 시계열 모델로 생성하였는데요. 이제 해당 개별 모델들이 추정한 방송이 끝난 한 시점 이후의 미래값을 비교하여 연습생들의 (추정 언급량)순위를 매겨 보겠습니다. 모델을 생성하였으면 미래값을 추정하는 것은 그리 어려운 일이 아닙니다. 지금까지 자주 사용하였던 forecast()함수를 사용하여 개개인의 미래값을 도출하고 이를 하나의 데이터프레임으로 묶겠습니다. library(purrr) compare_pred &lt;- final %&gt;% map(function(x){ x$model %&gt;% forecast(h = 7) %&gt;% as.data.frame() %&gt;% map_df(mean) }) %&gt;% do.call(rbind, .) compare_pred ## # A tibble: 20 x 5 ## `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95` ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1053. 670. 1436. 459. 1647. ## 2 2003. 725. 3280. 22.1 3983. ## 3 543. -188. 1274. -575. 1660. ## 4 1066. 631. 1501. 401. 1731. ## 5 1056. 365. 1747. -1.45 2113. ## 6 2184. 1502. 2865. 1127. 3240. ## 7 1031. 677. 1386. 481. 1582. ## 8 734. 269. 1199. 22.6 1445. ## 9 1153. 793. 1513. 594. 1711. ## 10 940. 512. 1368. 276. 1604. ## 11 611. 439. 782. 348. 873. ## 12 527. 291. 763. 162. 893. ## 13 891. 520. 1262. 315. 1467. ## 14 978. 504. 1451. 243. 1712. ## 15 1424. 654. 2194. 247. 2602. ## 16 542. 273. 811. 130. 953. ## 17 620. 236. 1004. 24.3 1216. ## 18 354. 144. 564. 32.8 676. ## 19 567. 239. 895. 64.9 1069. ## 20 278. 88.9 467. -11.0 566. 예측은 모델이 바로 1 시점 이후를 예측하는 것이 아닌 시계열 데이터가 지니고 있는 주기적인 반복성인 계절성의 영향을 고려하여 모델의 7 예측 시점 까지를 구하고 이를 평균낸 값을 활용하도록 하겠습니다. 각 모델별로 7 시점 미래 값을 평균내어 예측 신뢰구간과 함께 점추정값을 하나의 객체에 저장하였습니다. 여기서 비교의 대상이 될 점추정값(Point Forecast)값을 기준으로 연습생들을 재정렬, 이를 순위매겨보도록 하겠습니다. model_rank &lt;- compare_pred %&gt;% arrange(desc(`Point Forecast`)) %&gt;% mutate(rank = row_number(), boy = rownames(.)) %&gt;% select(rank, boy, `Point Forecast`) library(kableExtra) kable(model_rank, align = &#39;c&#39;) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = T, position = &quot;center&quot;) rank boy Point Forecast 1 조승연 2183.7551 2 김우석 2002.5306 3 구정모 1424.3354 4 이은상 1152.6122 5 한승우 1065.6902 6 김민규 1055.8778 7 김요한 1053.1224 8 남도현 1031.4286 9 강민희 977.6735 10 금동현 940.2449 11 황윤성 890.9592 12 송형준 733.9222 13 송유빈 619.9592 14 차준호 610.5810 15 토니 567.1067 16 이진혁 542.9184 17 이한결 541.5512 18 손동표 527.0816 19 함원진 354.2201 20 이세진 277.7153 모델이 추정한 미래값을 기준으로 최종 11명을 뽑자면 조승연, 김우석, 구정모, 이은상, 한승우, 김민규, 김요한, 남도현, 강민희, 금동현, 황윤성 순으로 뽑을 수 있겠습니다. 이전 5장에서 순위를 매겼던 방식인 방송 기간 중 연습생별 총 언급량 기준, 그리고 방송의 마지막 주차(11주차)를 기준으로 정렬한 언급량 순위랑 비교해보면 어떠한 차이가 있을지 비교해 보도록 하겠습니다. library(stringr) temp_mention &lt;- c() episode_mention &lt;- c() for(i in seq(1, 20)){ temp_mention &lt;- pxdata %&gt;% filter(str_detect(p_title, boylist2[i])) %&gt;% group_by(p_episode) %&gt;% summarise(mention =n()) %&gt;% mutate(boy = boylist[i]) episode_mention &lt;- rbind(episode_mention, temp_mention) } week11_rank &lt;- episode_mention %&gt;% filter(p_episode == 11) %&gt;% arrange(desc(mention)) %&gt;% mutate(week11_rank = row_number()) %&gt;% rename(week11_mention = mention) %&gt;% select(week11_rank, boy, week11_mention) total_rank &lt;- episode_mention %&gt;% group_by(boy) %&gt;% summarise(total_mention = sum(mention)) %&gt;% arrange(desc(total_mention)) %&gt;% mutate(total_rank = row_number()) %&gt;% select(total_rank, boy, total_mention) all_rank &lt;- model_rank %&gt;% rename(model_rank = rank) %&gt;% left_join(week11_rank, by = &#39;boy&#39;) %&gt;% left_join(total_rank , by = &#39;boy&#39;) %&gt;% select(model_rank, week11_rank, total_rank, boy, `Point Forecast`, week11_mention, total_mention) library(DT) my_table &lt;- function(dt){ dt %&gt;% datatable(rownames = F, options = list(dom = &#39;t&#39;, pageLength = 20, columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:6)), # column name 사이즈 조절 headerCallback = DT::JS( &quot;function(thead) {&quot;, &quot; $(thead).css(&#39;font-size&#39;, &#39;0.8em&#39;);&quot;, &quot;}&quot; ) ) ) %&gt;% formatRound(&quot;Point Forecast&quot;, 2) %&gt;% formatStyle(columns = colnames(.), fontSize = &#39;70%&#39;) } my_table(all_rank) 기준별로 순위는 상이하지만 상위권과 하위권이 대체로 유사하게 나타나는 것처럼 보입니다. 그렇다면 모델이 추정한 값의 순위, 11주차 기준 순위, 전체 언급량 순위 모두에서 데뷔 순위로 나타나는 연습생과 그렇지 않은 연습생은 어떠한지 보겠습니다. # 모든 기준에 들어가는 연습생 all_rank %&gt;% filter(model_rank %in% seq(1, 11)) %&gt;% filter(week11_rank %in% seq(1, 11)) %&gt;% filter(total_rank %in% seq(1, 11)) %&gt;% my_table() 모든 기준에서 최종 데뷔조로 나타나는 연습생은 각각 조승연, 김우석, 구정모, 이은상, 한승우, 김민규, 김요한, 남도현이 좋은 수치를 내는 것을 볼 수 있습니다. # 모든 기준에 들어가지 않는 연습생 all_rank %&gt;% filter(!model_rank %in% seq(1, 11)) %&gt;% filter(!week11_rank %in% seq(1, 11)) %&gt;% filter(!total_rank %in% seq(1, 11)) %&gt;% my_table() 한편 송유빈, 차준호, 토니, 이한결, 손동표, 함원진, 이세진 연습생들은 모든 기준에서도 데뷔조에 들어가지 않는것으로 나오고 있습니다. 하지만 해당 결과를 실제 예측에 반영하기는 무리가 있는점이 있습니다. 신뢰구간을 고려하지 않은 점추정 값의 비교는 자칫 치명적인 오류를 범할 수 있기 때문입니다. 예를들어 어느 두 사람의 추정값이 상대적으로 높게 나오더라도 신뢰구간이 겹치게 된다면 이는 실제 두사람의 결과가 얼마든지 바뀔 수 있기 때문입니다. final[[&#39;송형준&#39;]]$model %&gt;% forecast(h = 7) %&gt;% autoplot(conf.int.fill = &#39;royalblue1&#39;, conf.int.alpha = 0.2) + autolayer(final[[&#39;황윤성&#39;]]$model$data$sum_mention, color = &#39;violetred4&#39;) + autolayer(final[[&#39;황윤성&#39;]]$model %&gt;% forecast(h = 7), color = &#39;red&#39;, alpha = 0.2) + labs(title = &quot;황윤성 - 송형준 95% 신뢰구간 비교&quot;) 그래프에 붉은색으로 음영처리된 부분은 모델이 데뷔조의 마지막 등수인 11등으로 예측한 황윤성의 95% 신뢰구간을 표시한 것이고, 푸른색 음영처리 부분은 12등으로 예측한 송형준의 신뢰구간을 의미합니다. 신뢰구간인 즉슨 실제 값이 신뢰구간에 속할 확률이 95%란 의미인데 이처럼 겹쳐있는 부분이 존재하면 특히 겹쳐있는 부분의 범위가 넓을수록 쉽사리 누가 우위에 있는지를 속단하기 어려운 의미입니다. 또한 데이터의 출처를 생각해 보자면 특정 커뮤니티에서의 의견이기 때문이기 때문에 커뮤니티에 활동하는 유저의 성향에 따라 데이터가 편향이 될 가능성이 높습니다. 수집한 데이터의 출처가된 커뮤니티의 유저들이 전체 시청자들의 의견을 대변하는건 아니기 때문에 해당 모델링 결과를 통해 최종 예측을 하기엔 다소 무리가 있습니다. 그렇다면 진행한 모델링의 결과는 의미가 없냐? 또 그렇진 않습니다. 분석의 대전제가 된 언급량이 많을수록 인기가 있을것이다란 것에 맞춘 모델링이기에 여기서의 값이 높게 나온 연습생은 실제로 인기가 높은 연습생일 확률이 높습니다. 또한 높은 확률로 데뷔조에 속할 가능성이 있습니다. 실제로 모델의 예측치 순위에서 3위에 있는 구정모 연습생과 10위의 금동현 연습생은 제작진의 (조작된) 방송의 최종 순위에서는 탈락한 것으로 발표 되었지만 (재판 과정에서 드러난) 실제 순위에선 각각 6위, 8위를 기록하여 최종 데뷔조 였단 것이 밝혀졌었습니다. 모델의 결과를 전적으로 신뢰하긴 어렵지만 어떤 연습생이 인기가 있었는지 참고하기엔 좋은 자료인 것 같습니다. 지금까지 데이터 수집부터 모델 예측까지 다양한 절차를 통해 분석을 진행하였습니다. 최종 투표에서 조작이 있었다는 의혹으로 인해 지난해 말 프로듀스 X 101은 의혹에 대한 재판이 진행되었었고, 재판의 결과로 실제로 제작진의 투표조작이 있었다는 발표가 있었습니다. 처음 이 분석을 기획한 당시에 시청자들의 의견이 담긴 텍스트를 분석하면 최종적으로 선발될 연습생이 누군지 알 수 있지 않을까란 생각과, 이를 실제 결과와 대조하면 유의미한 결과가 있지 않을까 싶어 진행하였지만 실상은 모든것이 제작진의 조작이였다는 발표를 듣게 되니 약간은 허탈하면서도 평소 프로그램을 즐겨보던 한명의 시청자로서 아쉬운 발표이기도 했었습니다. 재판 이후에 나온 관련 기사들을 읽다보니 지금껏 너무 순진하게 방송국놈들을 믿었던건 아닌지 싶은 생각이 들기도 하더군요 ^^; 재판으로 밝혀진 사실이 궁금하신 분들은 판결문 전문 또는 잘 정리된 기사에서 확인 하실 수 있습니다. 이것으로 프로듀스 X 101 데뷔 예측 분석을 마치도록 하겠습니다. "]
]
